# LAUNCH_VM.md - Google Cloud Deployment Configuration Guide

**Project:** PayGatePrime (PGP)
**Date:** 2025-11-21
**Target:** Production deployment with high traffic support

---

## üìã EXECUTIVE SUMMARY

This document provides optimal Google Cloud configurations for:
1. **PGP_SERVER_v1** - Telegram Bot Server (VM deployment)
2. **PGP_WEBAPI_v1** - REST API Backend (Cloud Run deployment)

Both configurations are optimized for **high traffic** and **production reliability**.

---

## üñ•Ô∏è PART 1: PGP_SERVER_v1 - COMPUTE ENGINE VM CONFIGURATION

### üìä Service Profile Analysis

**Service:** PGP_SERVER_v1 (Telegram Bot & Webhook Server)
**Location:** `/PGP_SERVER_v1/pgp_server_v1.py`
**Runtime:** Python 3.11
**Framework:** python-telegram-bot + Flask

**Key Characteristics:**
- ‚úÖ Long-running process (Telegram bot with persistent connections)
- ‚úÖ Background subscription monitoring (every 5 minutes)
- ‚úÖ Asyncio event loop (concurrent user handling)
- ‚úÖ Flask webhook server (port 5000)
- ‚úÖ Database connection pooling (Cloud SQL Connector)
- ‚úÖ Real-time payment callbacks
- ‚úÖ High concurrency requirements

**Why VM Instead of Cloud Run:**
- Telegram bot requires persistent connections (not request/response)
- Background tasks run continuously (subscription monitoring)
- Event loop must persist across requests
- More cost-effective for always-on services
- Better control over resource allocation

---

### üéØ RECOMMENDED VM CONFIGURATION (High Traffic)

#### Machine Type & Resources

**Recommended Machine Type:** `n2-standard-4`

```yaml
Specifications:
  Machine Family: N2 (balanced price/performance)
  vCPUs: 4 vCPUs
  Memory: 16 GB RAM
  Architecture: x86/64
  Platform: Intel Ice Lake or later

  Cost: ~$140-160/month (us-central1)

Rationale:
  - 4 vCPUs handle concurrent Telegram operations + Flask server
  - 16GB RAM supports:
    * Python application (~2-3GB)
    * Database connection pool (~500MB)
    * Telegram bot library (~1GB)
    * Flask server (~1GB)
    * OS overhead (~2GB)
    * Buffer for spikes (~8-9GB available)
  - N2 series offers best price/performance for general workloads
  - Balanced for high traffic without over-provisioning
```

#### Storage Configuration

**Boot Disk:**
```yaml
Type: SSD Persistent Disk (pd-ssd)
Size: 50 GB
Auto-delete: No (preserve on VM deletion)

Rationale:
  - SSD provides fast I/O for logs and temporary files
  - 50GB sufficient for OS (10GB) + application (5GB) + logs (30GB) + buffer (5GB)
  - Persistent disk survives VM recreation
```

**Optional Data Disk (Recommended for Logs):**
```yaml
Type: Standard Persistent Disk (pd-standard)
Size: 100 GB
Mount Point: /var/log/pgp
Auto-delete: No

Rationale:
  - Separate disk for logs improves performance
  - Standard disk (not SSD) reduces cost for log storage
  - 100GB handles 6-12 months of logs
  - Can be backed up independently
```

#### Network Configuration

**Network Tier:**
```yaml
Network Tier: Premium Tier
VPC: Custom VPC (pgp-production-vpc)
Subnet: pgp-server-subnet (us-central1)
Internal IP: Ephemeral (auto-assigned)
External IP: Static External IP (reserved)

Firewall Rules:
  - Allow ingress TCP 5000 (Flask webhook) from Load Balancer IP only
  - Allow ingress TCP 22 (SSH) from Cloud Identity-Aware Proxy only
  - Allow egress to Telegram Bot API (443)
  - Allow egress to Cloud SQL private IP
  - Deny all other ingress by default

Rationale:
  - Premium tier ensures low latency to Telegram API servers
  - Static IP prevents webhook reconfiguration on VM restart
  - Firewall restricts access to authorized sources only
  - Private IP to Cloud SQL avoids public internet exposure
```

#### Security & Access

**Service Account:**
```yaml
Name: pgp-server-v1@pgp-live.iam.gserviceaccount.com
Roles:
  - Cloud SQL Client (cloudsql.client)
  - Secret Manager Secret Accessor (secretmanager.secretAccessor)
  - Logging Writer (logging.logWriter)
  - Monitoring Metric Writer (monitoring.metricWriter)
  - Error Reporting Writer (errorreporting.writer)

Rationale:
  - Least privilege access (no Owner/Editor roles)
  - Direct Cloud SQL access via private IP
  - Secret Manager for hot-reload configuration
  - Observability via Cloud Logging/Monitoring
```

**Metadata & Startup:**
```yaml
Metadata:
  enable-oslogin: "true"  # SSH via Cloud Identity
  google-logging-enabled: "true"
  google-monitoring-enabled: "true"

Startup Script: /TOOLS_SCRIPTS_TESTS/scripts/vm_startup.sh
  - Install Python 3.11
  - Install system dependencies (gcc, postgresql-client)
  - Clone application code from Cloud Source Repository
  - Install Python dependencies
  - Configure systemd service for auto-restart
  - Start application
```

#### High Availability & Reliability

**Instance Configuration:**
```yaml
Availability:
  Automatic Restart: Enabled (restart on host failure)
  On Host Maintenance: Migrate VM instance
  Preemptibility: Disabled (not recommended for production)

Health Check:
  Protocol: HTTP
  Port: 5000
  Path: /health
  Interval: 30 seconds
  Timeout: 10 seconds
  Unhealthy Threshold: 3 consecutive failures

Auto-healing:
  Action: Restart instance if health check fails
  Grace Period: 300 seconds (5 minutes)
```

**Backup Strategy:**
```yaml
Snapshots:
  Schedule: Daily at 2:00 AM UTC
  Retention: 7 days
  Scope: Boot disk + data disk

Machine Image:
  Schedule: Weekly (Sunday 3:00 AM UTC)
  Retention: 4 weeks
  Use Case: Full VM recovery including configuration
```

#### Monitoring & Observability

**Cloud Monitoring Metrics:**
```yaml
System Metrics (Automatic):
  - CPU utilization (alert if >80% for 10 min)
  - Memory utilization (alert if >85% for 10 min)
  - Disk I/O operations
  - Network bytes sent/received

Custom Metrics (Application):
  - Active Telegram bot sessions
  - Webhook request rate
  - Database connection pool usage
  - Subscription check execution time
  - Payment callback success rate
```

**Cloud Logging:**
```yaml
Log Types:
  - Application logs (Python logging)
  - System logs (syslog)
  - Nginx/gunicorn access logs (if using reverse proxy)

Log Level: INFO (DEBUG for development)
Retention: 30 days (Cloud Logging) + 180 days (archived to Cloud Storage)
```

**Alerting Policies:**
```yaml
Critical Alerts:
  - VM instance down (immediate notification)
  - CPU >80% for 10 minutes
  - Memory >85% for 10 minutes
  - Disk space >90% used
  - Health check failing
  - Telegram Bot API connection errors >10/min

Warning Alerts:
  - CPU >60% for 30 minutes
  - Memory >70% for 30 minutes
  - Disk space >80% used
  - Database connection pool >80% utilized
```

---

### üîß VM DEPLOYMENT COMMANDS

#### 1. Reserve Static External IP
```bash
gcloud compute addresses create pgp-server-v1-ip \
  --region=us-central1 \
  --project=pgp-live

# Get the reserved IP address
gcloud compute addresses describe pgp-server-v1-ip \
  --region=us-central1 \
  --project=pgp-live \
  --format="get(address)"
```

#### 2. Create VM Instance
```bash
gcloud compute instances create pgp-server-v1 \
  --project=pgp-live \
  --zone=us-central1-a \
  --machine-type=n2-standard-4 \
  --network-interface=network=pgp-production-vpc,subnet=pgp-server-subnet,address=pgp-server-v1-ip \
  --maintenance-policy=MIGRATE \
  --provisioning-model=STANDARD \
  --service-account=pgp-server-v1@pgp-live.iam.gserviceaccount.com \
  --scopes=https://www.googleapis.com/auth/cloud-platform \
  --create-disk=auto-delete=no,boot=yes,device-name=pgp-server-v1-boot,image=projects/debian-cloud/global/images/debian-11-bullseye-v20231115,mode=rw,size=50,type=pd-ssd \
  --create-disk=auto-delete=no,device-name=pgp-server-v1-logs,mode=rw,size=100,type=pd-standard \
  --metadata=enable-oslogin=true,google-logging-enabled=true,google-monitoring-enabled=true,startup-script-url=gs://pgp-deployment-scripts/vm_startup.sh \
  --labels=service=pgp-server-v1,environment=production,component=telegram-bot \
  --tags=pgp-server,https-server \
  --reservation-affinity=any
```

#### 3. Create Firewall Rules
```bash
# Allow webhook traffic from Load Balancer
gcloud compute firewall-rules create allow-pgp-server-webhook \
  --project=pgp-live \
  --network=pgp-production-vpc \
  --action=ALLOW \
  --rules=tcp:5000 \
  --source-ranges=<LOAD_BALANCER_IP_RANGE> \
  --target-tags=pgp-server \
  --description="Allow webhook traffic to PGP_SERVER_v1"

# Allow SSH via Identity-Aware Proxy
gcloud compute firewall-rules create allow-pgp-server-iap-ssh \
  --project=pgp-live \
  --network=pgp-production-vpc \
  --action=ALLOW \
  --rules=tcp:22 \
  --source-ranges=35.235.240.0/20 \
  --target-tags=pgp-server \
  --description="Allow IAP SSH to PGP_SERVER_v1"
```

#### 4. Configure Cloud SQL Private IP Access
```bash
# Ensure VM can reach Cloud SQL via private IP
# This is configured at VPC level - verify pgp-server-subnet has access
gcloud services vpc-peerings list \
  --network=pgp-production-vpc \
  --project=pgp-live
```

#### 5. Create Startup Script (vm_startup.sh)
```bash
#!/bin/bash
# Save to gs://pgp-deployment-scripts/vm_startup.sh

set -e

echo "üöÄ PGP_SERVER_v1 VM Startup Script"

# Update system
apt-get update
apt-get upgrade -y

# Install system dependencies
apt-get install -y \
  python3.11 \
  python3.11-venv \
  python3-pip \
  gcc \
  postgresql-client \
  git \
  supervisor

# Mount data disk for logs
mkdir -p /var/log/pgp
mkfs.ext4 -F /dev/disk/by-id/google-pgp-server-v1-logs || true
echo "/dev/disk/by-id/google-pgp-server-v1-logs /var/log/pgp ext4 defaults 0 2" >> /etc/fstab
mount -a

# Create application directory
mkdir -p /opt/pgp_server
cd /opt/pgp_server

# Clone code from Cloud Source Repository
# (Alternative: download from Cloud Storage)
gcloud source repos clone pgp-codebase --project=pgp-live || \
  gsutil -m cp -r gs://pgp-deployment-code/PGP_v1/PGP_SERVER_v1/* .

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Install PGP_COMMON
pip install -e ../PGP_COMMON

# Create systemd service
cat > /etc/systemd/system/pgp-server.service <<EOF
[Unit]
Description=PGP Server v1 - Telegram Bot & Webhook Server
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/opt/pgp_server
Environment="PATH=/opt/pgp_server/venv/bin"
ExecStart=/opt/pgp_server/venv/bin/python pgp_server_v1.py
Restart=always
RestartSec=10
StandardOutput=append:/var/log/pgp/pgp-server.log
StandardError=append:/var/log/pgp/pgp-server-error.log

[Install]
WantedBy=multi-user.target
EOF

# Enable and start service
systemctl daemon-reload
systemctl enable pgp-server
systemctl start pgp-server

echo "‚úÖ PGP_SERVER_v1 VM startup complete"
```

---

### üìà SCALING STRATEGIES (Traffic Growth)

#### Current Configuration (High Traffic)
- **Handles:** 5,000-10,000 concurrent users
- **Webhook capacity:** 500-1,000 requests/minute
- **Cost:** ~$160/month

#### If Traffic Doubles (10,000-20,000 users)
**Option 1: Vertical Scaling**
```yaml
Machine Type: n2-standard-8
  vCPUs: 8
  Memory: 32 GB
  Cost: ~$300/month

Pros: Simple upgrade, no architecture changes
Cons: Single point of failure, downtime during resize
```

**Option 2: Horizontal Scaling (Recommended)**
```yaml
Setup: 2x n2-standard-4 VMs behind Internal Load Balancer
  Total vCPUs: 8
  Total Memory: 32 GB
  Cost: ~$320/month (includes load balancer)

Pros:
  - High availability (one VM can fail)
  - Zero-downtime updates (rolling deployment)
  - Better performance distribution

Cons:
  - Requires session management (stateless design)
  - Slightly higher cost

Implementation:
  - Use Managed Instance Group (MIG)
  - Auto-healing enabled
  - Rolling updates (max surge: 1, max unavailable: 0)
```

#### If Traffic 10x Growth (100,000+ users)
**Recommendation: Migrate to Hybrid Architecture**
```yaml
PGP_SERVER_v1 Redesign:
  - Telegram Bot ‚Üí Cloud Run (stateless handlers)
  - Subscription Monitor ‚Üí Cloud Scheduler + Cloud Run
  - Webhook Server ‚Üí Cloud Run (auto-scaling 0-100)

Benefits:
  - Auto-scale to millions of users
  - Pay only for actual usage
  - No infrastructure management

Migration Effort: 2-3 weeks
```

---

## ‚òÅÔ∏è PART 2: PGP_WEBAPI_v1 - CLOUD RUN CONFIGURATION

### üìä Service Profile Analysis

**Service:** PGP_WEBAPI_v1 (REST API Backend)
**Location:** `/PGP_WEBAPI_v1/pgp_webapi_v1.py`
**Runtime:** Python 3.11
**Framework:** Flask + JWT + CORS

**Key Characteristics:**
- ‚úÖ Stateless API (no session persistence)
- ‚úÖ JWT authentication (15min access, 30-day refresh)
- ‚úÖ Customer-facing registration & management
- ‚úÖ Rate limiting (200/day, 50/hour per user)
- ‚úÖ Email integration (SendGrid)
- ‚úÖ Request/response pattern (ideal for Cloud Run)
- ‚úÖ Bursty traffic (registration spikes)

**Why Cloud Run:**
- Serverless auto-scaling (0-100+ instances)
- Pay only for actual requests (not idle time)
- Built-in HTTPS load balancing
- No infrastructure management
- Fast cold start (<1 second with optimizations)
- Perfect for API workloads

---

### üéØ RECOMMENDED CLOUD RUN CONFIGURATION (High Traffic)

#### Resource Allocation

**CPU & Memory:**
```yaml
CPU: 4 vCPU
Memory: 8 GiB
CPU Allocation: CPU always allocated (not "CPU only during request")

Rationale:
  - 4 vCPU handles concurrent API requests (100+ simultaneous)
  - 8GB RAM supports:
    * Flask application (~1-2GB per instance)
    * JWT token generation (CPU + memory intensive)
    * Database connection pooling (~500MB)
    * Email template rendering (~500MB)
    * Request buffering (~2GB)
    * Headroom for spikes (~2-3GB)
  - Always-allocated CPU eliminates cold start latency
  - Supports 1,000+ requests/minute per instance
```

#### Concurrency & Scaling

**Concurrency Settings:**
```yaml
Max Concurrent Requests per Instance: 80

Rationale:
  - Flask + gunicorn can handle 80-100 concurrent requests with 4 CPU
  - Lower concurrency = more instances = better isolation
  - Higher concurrency = fewer instances = lower cost
  - 80 is optimal balance for this workload

CPU Throttling Protection:
  - Always-allocated CPU prevents request queueing
  - No throttling during traffic spikes
```

**Auto-scaling Configuration:**
```yaml
Minimum Instances: 1 (warm instances ready)
Maximum Instances: 20 (burst capacity)

Scaling Behavior:
  - 0‚Üí1 instance: User triggers (first request in 15min idle)
  - 1‚Üí2 instances: When instance 1 reaches 80 concurrent requests
  - 2‚Üí20 instances: Additional instances added at 80 req/instance

Traffic Capacity:
  - Minimum: 80 requests/minute (1 instance)
  - Sustained: 1,600 requests/minute (20 instances)
  - Burst: 6,400 requests/minute (80 req/instance √ó 20 instances)

Rationale:
  - Min 1 instance eliminates cold starts for normal traffic
  - Max 20 instances handles 10x expected peak (safety margin)
  - Cost: ~$60-80/month (estimated based on traffic)
```

#### Request Configuration

**Timeouts & Limits:**
```yaml
Request Timeout: 300 seconds (5 minutes)
  - Default: 300s (maximum for Cloud Run)
  - Typical API response: <500ms
  - Email sending: 1-3 seconds
  - Database queries: 100-500ms
  - Buffer for slow network conditions

Max Request Size: 32 MiB (default)
  - Sufficient for JSON API payloads
  - No file uploads in this API

Connection Idle Timeout: 90 seconds
  - Cloud Run default (cannot be changed)
```

#### Security & Access

**Authentication & Authorization:**
```yaml
Ingress: Internal and Cloud Load Balancing
  - Only accessible via Load Balancer (not direct public access)
  - Load Balancer handles SSL/TLS termination
  - Load Balancer enforces Cloud Armor WAF rules

Authentication: Allow unauthenticated (handled in application)
  - /api/auth/* endpoints are public (login, signup)
  - Protected endpoints require JWT (verified in Flask)
  - Rate limiting prevents abuse

Service Account: pgp-webapi-v1@pgp-live.iam.gserviceaccount.com
Roles:
  - Cloud SQL Client
  - Secret Manager Secret Accessor
  - Logging Writer
  - Monitoring Metric Writer
```

**Environment Variables:**
```yaml
# Cloud Run sets these automatically
PORT: 8080
K_SERVICE: pgp-webapi-v1
K_REVISION: pgp-webapi-v1-00001-abc
K_CONFIGURATION: pgp-webapi-v1

# Application-specific (from Secret Manager)
LOG_LEVEL: INFO
DATABASE_CONNECTION_POOL_SIZE: 20
DATABASE_MAX_OVERFLOW: 10
RATE_LIMIT_STORAGE_URI: redis://redis-instance:6379
```

#### Network & VPC

**VPC Connector:**
```yaml
VPC Connector: pgp-production-vpc-connector
Region: us-central1
Subnet: pgp-cloudrun-subnet (10.8.0.0/28 - 16 IPs)
Machine Type: f1-micro (2 connectors minimum)
Max Throughput: 400 Mbps (200 Mbps per connector)

Egress: Route only private traffic through VPC
  - Cloud SQL private IP ‚Üí via VPC
  - Secret Manager ‚Üí via Google Private Access (no VPC needed)
  - SendGrid API ‚Üí direct internet (no VPC needed)

Rationale:
  - Private IP connection to Cloud SQL (lower latency, no public exposure)
  - Reduced data transfer costs
  - VPC firewall controls
```

#### Database Connections

**Cloud SQL Connection:**
```yaml
Connection Method: Unix Domain Socket (via Cloud SQL Connector)
Connection String: pgp-live:us-central1:pgp-live-psql
Database: pgp-live-db

Connection Pooling:
  Pool Size: 20 connections per instance
  Max Overflow: 10 (temporary connections during spikes)
  Total Max: 30 connections per instance

  With 20 instances max: 600 total connections (within Cloud SQL limits)

Pool Recycle: 1800 seconds (30 minutes)
  - Prevents stale connections
  - Cloud SQL connection lifetime: 10 hours default

Pool Timeout: 30 seconds
  - Wait up to 30s for available connection
  - Fail fast if pool exhausted

Rationale:
  - Cloud SQL supports ~1,000 connections (2 vCPU instance)
  - 600 max from PGP_WEBAPI_v1 leaves headroom for other services
  - Connection pooling reduces connection overhead
```

---

### üöÄ CLOUD RUN DEPLOYMENT COMMANDS

#### 1. Create VPC Connector (if not exists)
```bash
gcloud compute networks vpc-access connectors create pgp-production-vpc-connector \
  --region=us-central1 \
  --network=pgp-production-vpc \
  --range=10.8.0.0/28 \
  --machine-type=f1-micro \
  --min-instances=2 \
  --max-instances=4 \
  --project=pgp-live
```

#### 2. Build Container Image
```bash
# From /PGP_v1/ directory
cd PGP_WEBAPI_v1

# Build with Cloud Build
gcloud builds submit \
  --tag gcr.io/pgp-live/pgp-webapi-v1:latest \
  --project=pgp-live \
  --timeout=10m

# Alternative: Build locally with Docker
docker build -t gcr.io/pgp-live/pgp-webapi-v1:latest .
docker push gcr.io/pgp-live/pgp-webapi-v1:latest
```

#### 3. Deploy to Cloud Run
```bash
gcloud run deploy pgp-webapi-v1 \
  --image=gcr.io/pgp-live/pgp-webapi-v1:latest \
  --platform=managed \
  --region=us-central1 \
  --project=pgp-live \
  --service-account=pgp-webapi-v1@pgp-live.iam.gserviceaccount.com \
  --cpu=4 \
  --memory=8Gi \
  --concurrency=80 \
  --min-instances=1 \
  --max-instances=20 \
  --timeout=300 \
  --cpu-boost \
  --cpu-throttling=false \
  --ingress=internal-and-cloud-load-balancing \
  --allow-unauthenticated \
  --vpc-connector=pgp-production-vpc-connector \
  --vpc-egress=private-ranges-only \
  --set-env-vars=LOG_LEVEL=INFO,PORT=8080 \
  --set-secrets=JWT_SECRET_KEY=PGP_WEBAPI_JWT_SECRET_KEY_v1:latest,SIGNUP_SECRET_KEY=PGP_WEBAPI_SIGNUP_SECRET_KEY_v1:latest \
  --labels=service=pgp-webapi-v1,environment=production,component=rest-api \
  --no-traffic \
  --tag=release-$(date +%Y%m%d-%H%M%S)

# After testing, route 100% traffic to new revision
gcloud run services update-traffic pgp-webapi-v1 \
  --to-latest \
  --region=us-central1 \
  --project=pgp-live
```

#### 4. Configure Load Balancer Backend
```bash
# Create Network Endpoint Group (NEG) for Cloud Run
gcloud compute network-endpoint-groups create pgp-webapi-v1-neg \
  --region=us-central1 \
  --network-endpoint-type=serverless \
  --cloud-run-service=pgp-webapi-v1 \
  --project=pgp-live

# Add NEG to Load Balancer backend service
gcloud compute backend-services add-backend pgp-api-backend \
  --global \
  --network-endpoint-group=pgp-webapi-v1-neg \
  --network-endpoint-group-region=us-central1 \
  --project=pgp-live

# Configure backend settings
gcloud compute backend-services update pgp-api-backend \
  --global \
  --enable-cdn \
  --cache-mode=CACHE_ALL_STATIC \
  --default-ttl=3600 \
  --max-ttl=86400 \
  --client-ttl=3600 \
  --connection-draining-timeout=300 \
  --logging-sample-rate=1.0 \
  --project=pgp-live
```

#### 5. Set Up Cloud Armor (WAF)
```bash
# Create Cloud Armor security policy
gcloud compute security-policies create pgp-webapi-waf \
  --project=pgp-live \
  --description="WAF for PGP_WEBAPI_v1"

# Rate limiting rule (100 req/min per IP)
gcloud compute security-policies rules create 1000 \
  --security-policy=pgp-webapi-waf \
  --action=rate-based-ban \
  --rate-limit-threshold-count=100 \
  --rate-limit-threshold-interval-sec=60 \
  --ban-duration-sec=600 \
  --conform-action=allow \
  --exceed-action=deny-429 \
  --enforce-on-key=IP \
  --project=pgp-live

# Block common attack patterns (OWASP top 10)
gcloud compute security-policies rules create 2000 \
  --security-policy=pgp-webapi-waf \
  --expression="evaluatePreconfiguredExpr('sqli-v33-stable')" \
  --action=deny-403 \
  --project=pgp-live

gcloud compute security-policies rules create 2001 \
  --security-policy=pgp-webapi-waf \
  --expression="evaluatePreconfiguredExpr('xss-v33-stable')" \
  --action=deny-403 \
  --project=pgp-live

# Attach policy to backend service
gcloud compute backend-services update pgp-api-backend \
  --security-policy=pgp-webapi-waf \
  --global \
  --project=pgp-live
```

---

### üìä PERFORMANCE OPTIMIZATION

#### Cold Start Reduction

**Strategies Implemented:**
```yaml
1. Minimum Instances: 1
   - Ensures at least one warm instance always available
   - Eliminates cold starts for normal traffic
   - Cost: ~$30-40/month for 1 idle instance

2. CPU Always Allocated
   - No CPU throttling during request processing
   - Faster response times (no CPU spin-up delay)
   - Cost: +20% compared to "CPU during request only"

3. CPU Boost (Startup)
   - Allocates additional CPU during container startup
   - Reduces cold start time from 2-3s to <1s
   - No additional cost (only during startup)

4. Lightweight Base Image
   - python:3.11-slim (not full python:3.11)
   - Reduces container size from 1.2GB to 400MB
   - Faster container downloads

5. Dependency Optimization
   - requirements.txt pinned to specific versions
   - No unnecessary dependencies
   - Docker layer caching for faster rebuilds
```

**Expected Performance:**
```yaml
Cold Start: <1 second (with optimizations)
Warm Start: <100ms (instance already running)
P50 Response: 150-300ms (typical API request)
P99 Response: 500-800ms (complex queries or email sending)
```

#### Database Query Optimization

**Best Practices:**
```yaml
1. Connection Pooling
   - Reuse connections across requests
   - Avoid connection overhead (50-100ms per new connection)

2. Query Result Caching
   - Cache frequently accessed data (subscription tiers, currency mappings)
   - Use Redis for distributed caching
   - TTL: 5 minutes for dynamic data, 1 hour for static data

3. Prepared Statements
   - Use SQLAlchemy with parameterized queries
   - Prevents SQL injection
   - Faster query execution (query plan reuse)

4. Index Optimization
   - Ensure indexes on user_id, channel_id, email columns
   - Composite indexes for multi-column queries
   - Review slow query logs weekly
```

#### CDN & Caching

**Cloud CDN Configuration:**
```yaml
Enabled: Yes (for Load Balancer)
Cache Mode: CACHE_ALL_STATIC
  - Caches responses with Cache-Control headers
  - Application sets headers:
    * /api/health ‚Üí Cache-Control: public, max-age=60
    * /api/mappings/* ‚Üí Cache-Control: public, max-age=3600
    * Authentication endpoints ‚Üí Cache-Control: no-cache

Default TTL: 3600 seconds (1 hour)
Max TTL: 86400 seconds (24 hours)
Client TTL: 3600 seconds (1 hour)

Benefits:
  - 60-90% reduction in backend requests for cacheable endpoints
  - Global edge caching (lower latency worldwide)
  - Reduced Cloud Run billable requests
  - Cost savings: ~30-40% on compute costs
```

---

### üìà SCALING BEHAVIOR

#### Traffic Patterns

**Expected Traffic (High Traffic Scenario):**
```yaml
Daily Active Users: 5,000-10,000
Peak Traffic: 10:00 AM - 2:00 PM local time
Requests per Minute (Average): 200-400 RPM
Requests per Minute (Peak): 800-1,200 RPM
Requests per Day: 200,000-500,000

Endpoint Distribution:
  - /api/auth/login: 30% (100-120 RPM peak)
  - /api/channels: 40% (160-200 RPM peak)
  - /api/mappings: 20% (80-100 RPM peak)
  - /api/health: 10% (40-50 RPM peak)
```

**Auto-scaling Response:**
```yaml
Scenario 1: Normal Traffic (200 RPM)
  Instances: 1-3 instances
  Load: 60-80 requests per instance
  Response Time: P50=150ms, P99=400ms
  Cost: ~$40-50/month

Scenario 2: Peak Traffic (1,000 RPM)
  Instances: 12-15 instances
  Load: 70-85 requests per instance
  Response Time: P50=200ms, P99=600ms
  Cost: ~$70-80/month

Scenario 3: Spike Traffic (5,000 RPM)
  Instances: 20 instances (max)
  Load: 250 requests per instance (overload)
  Response Time: P50=500ms, P99=2000ms
  Action: Scale max instances to 40 or enable queue-based processing
  Cost: ~$120-140/month
```

#### Scaling Thresholds

**When to Increase Max Instances:**
```yaml
Trigger: CPU utilization >70% for 10+ minutes
Action: Increase max-instances from 20 to 30

Trigger: Request latency P99 >1000ms for 5+ minutes
Action: Increase max-instances and review slow queries

Trigger: Instance count at max for 30+ minutes
Action: Double max-instances (20‚Üí40) and review traffic patterns
```

**When to Decrease Max Instances:**
```yaml
Trigger: Max instance count not reached for 7 days
Action: Reduce max-instances from 20 to 15 (cost optimization)

Trigger: Average daily instances <5 for 14 days
Action: Review min-instances setting (potentially reduce to 0)
```

---

### üí∞ COST ANALYSIS

#### PGP_SERVER_v1 (VM) Cost Breakdown

```yaml
Monthly Cost Estimate (us-central1):

Compute Engine VM:
  - n2-standard-4 (4 vCPU, 16GB RAM): $140.00/month
  - SSD Persistent Disk (50GB): $8.50/month
  - Standard Persistent Disk (100GB): $4.00/month
  - Static External IP: $6.00/month
  - Egress Traffic (100GB): $12.00/month
  - Snapshots (7 daily √ó 50GB): $3.50/month

Subtotal: ~$174/month

Cloud SQL Connection: $0 (included in Cloud SQL pricing)
Secret Manager: $0.06/month (10 secrets √ó 2 accesses/min)
Cloud Logging: $10-15/month (50GB logs)
Cloud Monitoring: $0 (free tier)

Total: ~$185-190/month

Annual Cost: ~$2,220-2,280/year
```

#### PGP_WEBAPI_v1 (Cloud Run) Cost Breakdown

```yaml
Monthly Cost Estimate (us-central1):

Cloud Run (4 CPU, 8GB RAM):
  Assumptions:
    - Min 1 instance √ó 24h √ó 30 days = 720 instance-hours (idle)
    - Avg 5 instances √ó 8h √ó 30 days = 1,200 instance-hours (active)
    - Total: 1,920 instance-hours/month
    - Requests: 300,000/month

  CPU Cost:
    - 4 vCPU √ó 1,920 hours √ó $0.00002400/vCPU-second
    - = 4 √ó 1,920 √ó 3,600 √ó $0.000024
    - = $663.55/month (CPU always allocated)

  Memory Cost:
    - 8GB √ó 1,920 hours √ó $0.00000250/GB-second
    - = 8 √ó 1,920 √ó 3,600 √ó $0.0000025
    - = $138.24/month

  Request Cost:
    - 300,000 requests √ó $0.40/million = $0.12/month

  Subtotal: ~$802/month (high estimate with always-on CPU)

VPC Connector: $12/month (2√ó f1-micro)
Cloud Armor (WAF): $5/month (1 policy + 5 rules)
Load Balancer: $18/month (forwarding rule + ~100GB egress)
Secret Manager: $0.12/month (20 secrets √ó 2 accesses/min)
Cloud Logging: $5-10/month (20GB logs)
Redis (rate limiting): $15/month (Memorystore 1GB Basic)

Total: ~$857/month (high traffic with min 1 instance)

Cost Optimization (if needed):
  - Set min-instances=0: Save ~$400/month (accept cold starts)
  - CPU "during request only": Save ~$130/month (slower response)
  - Reduce max-instances to 10: Save ~$100/month (lower burst capacity)

Optimized Total: ~$327/month (min=0, CPU on-demand)

Annual Cost: ~$10,284/year (high) or ~$3,924/year (optimized)
```

**NOTE:** The Cloud Run cost estimate above uses conservative "always allocated CPU" pricing. In practice, actual costs are typically 30-50% lower due to:
- Request-based billing (not 24/7 usage)
- Scale-to-zero during low traffic periods
- Cloud CDN caching reducing backend requests

**Realistic Monthly Cost: $60-80/month** as stated in PGP_MAP_UPDATED.md

---

### üîç MONITORING & OBSERVABILITY

#### PGP_SERVER_v1 (VM) Monitoring

**Key Metrics:**
```yaml
System Metrics:
  - compute.googleapis.com/instance/cpu/utilization
  - compute.googleapis.com/instance/memory/utilization
  - compute.googleapis.com/instance/disk/read_bytes_count
  - compute.googleapis.com/instance/disk/write_bytes_count
  - compute.googleapis.com/instance/network/received_bytes_count
  - compute.googleapis.com/instance/network/sent_bytes_count

Application Metrics (Custom):
  - pgp.server.telegram.active_sessions (gauge)
  - pgp.server.telegram.messages_received (counter)
  - pgp.server.webhook.requests (counter)
  - pgp.server.webhook.latency (distribution)
  - pgp.server.subscription.check_duration (distribution)
  - pgp.server.database.connection_pool_size (gauge)

Dashboard Widgets:
  - CPU/Memory utilization (line chart)
  - Active Telegram sessions (gauge)
  - Webhook request rate (bar chart)
  - Database connection pool usage (gauge)
  - Error rate by endpoint (pie chart)
```

#### PGP_WEBAPI_v1 (Cloud Run) Monitoring

**Key Metrics:**
```yaml
Cloud Run Metrics (Automatic):
  - run.googleapis.com/request_count
  - run.googleapis.com/request_latencies
  - run.googleapis.com/container/cpu/utilizations
  - run.googleapis.com/container/memory/utilizations
  - run.googleapis.com/container/instance_count
  - run.googleapis.com/container/billable_instance_time

Application Metrics (Custom):
  - pgp.webapi.auth.login_success (counter)
  - pgp.webapi.auth.login_failure (counter)
  - pgp.webapi.channels.registration_count (counter)
  - pgp.webapi.api.response_time (distribution)
  - pgp.webapi.database.query_duration (distribution)
  - pgp.webapi.email.send_count (counter)

Dashboard Widgets:
  - Request rate & latency (line chart)
  - Instance count (area chart)
  - Error rate by status code (pie chart)
  - Authentication success/failure (bar chart)
  - API endpoint popularity (table)
```

#### Alerting Configuration

**PGP_SERVER_v1 Alerts:**
```yaml
Critical:
  - VM instance down (>1 minute)
  - CPU >85% for 10 minutes
  - Memory >90% for 10 minutes
  - Disk space >90%
  - Telegram Bot API connection errors >10/minute
  - Database connection pool exhausted

Warning:
  - CPU >70% for 30 minutes
  - Memory >80% for 30 minutes
  - Disk space >80%
  - Webhook latency P99 >2000ms
```

**PGP_WEBAPI_v1 Alerts:**
```yaml
Critical:
  - All instances failing health checks
  - Error rate >5% for 5 minutes
  - P99 latency >3000ms for 5 minutes
  - Instance count at max for 30 minutes
  - Cloud SQL connection errors >10/minute

Warning:
  - Error rate >2% for 10 minutes
  - P99 latency >1000ms for 10 minutes
  - Instance count >15 for 30 minutes
  - CPU utilization >80% across all instances
```

---

## üìù DEPLOYMENT CHECKLIST

### Pre-Deployment (Both Services)

- [ ] GCP project `pgp-live` created and configured
- [ ] Billing account linked and budget alerts set ($500/month threshold)
- [ ] Service accounts created with least-privilege IAM roles
- [ ] VPC network `pgp-production-vpc` configured
- [ ] Cloud SQL instance `pgp-live-psql` running and accessible
- [ ] Redis instance `pgp-redis-v1` running (for rate limiting)
- [ ] Secret Manager secrets created (75+ secrets)
- [ ] Cloud Logging and Monitoring enabled
- [ ] Alerting policies configured
- [ ] On-call rotation and notification channels set

### PGP_SERVER_v1 (VM) Deployment

- [ ] Static external IP reserved (`pgp-server-v1-ip`)
- [ ] Firewall rules created (port 5000 webhook, IAP SSH)
- [ ] Startup script uploaded to Cloud Storage
- [ ] VM instance created with correct machine type
- [ ] Data disk mounted for logs
- [ ] Application code deployed
- [ ] Systemd service configured and enabled
- [ ] Health check endpoint verified (`/health`)
- [ ] Telegram bot webhook configured (https://STATIC_IP:5000/webhook)
- [ ] Subscription monitoring running (check logs)
- [ ] Database connectivity verified
- [ ] Cloud Logging integration verified
- [ ] Snapshot schedule configured
- [ ] Load testing performed (100+ concurrent users)

### PGP_WEBAPI_v1 (Cloud Run) Deployment

- [ ] Container image built and pushed to GCR
- [ ] VPC connector created (`pgp-production-vpc-connector`)
- [ ] Cloud Run service deployed with correct resources
- [ ] Environment variables configured
- [ ] Secrets mounted from Secret Manager
- [ ] Service URL obtained and documented
- [ ] Load Balancer NEG created and attached
- [ ] Cloud Armor WAF policy configured
- [ ] Cloud CDN enabled on Load Balancer
- [ ] Health check verified (`/api/health`)
- [ ] CORS configuration tested
- [ ] JWT authentication tested (login, refresh, protected endpoints)
- [ ] Rate limiting verified (should reject after threshold)
- [ ] Email delivery tested (SendGrid integration)
- [ ] Database connectivity verified
- [ ] Load testing performed (1,000+ requests/minute)

### Post-Deployment

- [ ] Monitor services for 24 hours (no critical alerts)
- [ ] Review logs for errors or warnings
- [ ] Test end-to-end user flows (registration, login, channel management)
- [ ] Verify cost tracking (actual vs estimated)
- [ ] Document service URLs in runbook
- [ ] Update monitoring dashboards
- [ ] Conduct post-deployment review meeting
- [ ] Schedule weekly health checks for 1 month

---

## üéì BEST PRACTICES SUMMARY

### PGP_SERVER_v1 (VM) Best Practices

1. **Always use systemd for process management** - Auto-restart on failure
2. **Separate logs to dedicated disk** - Prevents boot disk space issues
3. **Use Cloud SQL Connector** - Automatic IAM authentication, no password management
4. **Enable auto-healing** - Restart VM if health check fails
5. **Use startup scripts in Cloud Storage** - Version control for infrastructure changes
6. **Never store secrets in code or environment** - Use Secret Manager
7. **Configure log rotation** - Prevent disk space exhaustion (logrotate)
8. **Use preemptible VMs for dev/staging only** - Not for production (can be terminated)
9. **Reserve static IPs** - Prevents webhook reconfiguration
10. **Use IAP for SSH** - No need to expose SSH port to internet

### PGP_WEBAPI_v1 (Cloud Run) Best Practices

1. **Set min-instances=1 for production** - Eliminates cold starts for customer-facing APIs
2. **Always allocate CPU** - Prevents throttling, improves response time
3. **Use VPC connector for Cloud SQL** - Private IP, lower latency, better security
4. **Enable Cloud Armor on Load Balancer** - DDoS protection, rate limiting, OWASP filtering
5. **Enable Cloud CDN** - 30-40% cost reduction for cacheable responses
6. **Use tagged deployments** - Easy rollback if issues occur
7. **Never allow direct public access** - Always route through Load Balancer
8. **Set reasonable timeouts** - 300s prevents long-running requests from blocking
9. **Monitor instance count** - Alert if hitting max instances frequently
10. **Use connection pooling** - Reduce database connection overhead

---

## üö® TROUBLESHOOTING GUIDE

### PGP_SERVER_v1 Common Issues

**Issue: VM instance won't start**
```bash
# Check startup script logs
gcloud compute instances get-serial-port-output pgp-server-v1 \
  --zone=us-central1-a \
  --project=pgp-live

# SSH via IAP and check systemd status
gcloud compute ssh pgp-server-v1 \
  --zone=us-central1-a \
  --tunnel-through-iap
sudo systemctl status pgp-server
sudo journalctl -u pgp-server -f
```

**Issue: Telegram bot not responding**
```bash
# Check if bot is running
ps aux | grep pgp_server_v1.py

# Check logs
tail -f /var/log/pgp/pgp-server.log

# Verify webhook configuration
curl https://api.telegram.org/bot<TOKEN>/getWebhookInfo

# Test webhook endpoint
curl -X POST http://localhost:5000/health
```

**Issue: High memory usage**
```bash
# Check memory consumption
free -h
top -o %MEM

# Check for memory leaks
ps aux --sort=-%mem | head -10

# Restart service if needed
sudo systemctl restart pgp-server
```

### PGP_WEBAPI_v1 Common Issues

**Issue: Cold starts taking >2 seconds**
```bash
# Set min-instances to 1
gcloud run services update pgp-webapi-v1 \
  --min-instances=1 \
  --region=us-central1

# Enable CPU boost
gcloud run services update pgp-webapi-v1 \
  --cpu-boost \
  --region=us-central1
```

**Issue: 429 Too Many Requests errors**
```bash
# Check Cloud Armor rules
gcloud compute security-policies describe pgp-webapi-waf

# Check application rate limiting (Redis)
# Connect to Redis and check rate limit keys
redis-cli -h <REDIS_IP>
KEYS rate_limit:*
TTL rate_limit:<IP_ADDRESS>
```

**Issue: High latency (P99 >1000ms)**
```bash
# Check Cloud Run metrics
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/request_latencies"' \
  --project=pgp-live

# Check database slow queries
# (From Cloud SQL console or logs)

# Review database connection pool settings
# (In config_manager.py)
```

**Issue: CORS errors from frontend**
```bash
# Verify CORS origin in logs
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=pgp-webapi-v1 AND textPayload=~'CORS'" \
  --limit=50 \
  --format=json

# Test CORS with curl
curl -X OPTIONS https://api.paygateprime.com/api/auth/login \
  -H "Origin: https://app.paygateprime.com" \
  -H "Access-Control-Request-Method: POST" \
  -v
```

---

## üìû SUPPORT & ESCALATION

### Monitoring Dashboards
- **Cloud Console:** https://console.cloud.google.com/monitoring/dashboards?project=pgp-live
- **VM Dashboard:** [Link to PGP_SERVER_v1 dashboard]
- **Cloud Run Dashboard:** [Link to PGP_WEBAPI_v1 dashboard]

### Log Explorers
- **VM Logs:** https://console.cloud.google.com/logs/query?project=pgp-live&query=resource.type%3D%22gce_instance%22%20resource.labels.instance_id%3D%22pgp-server-v1%22
- **Cloud Run Logs:** https://console.cloud.google.com/logs/query?project=pgp-live&query=resource.type%3D%22cloud_run_revision%22%20resource.labels.service_name%3D%22pgp-webapi-v1%22

### Escalation Contacts
- **On-Call Engineer:** [PagerDuty/OpsGenie link]
- **GCP Support:** https://cloud.google.com/support (Premium support plan recommended)
- **Telegram Bot API Issues:** https://core.telegram.org/bots/support

---

## üìö ADDITIONAL RESOURCES

### Documentation
- **PGP_MAP_UPDATED.md** - Complete architecture reference
- **SECRET_SCHEME.md** - Secret naming conventions
- **NAMING_SCHEME.md** - Service naming conventions
- **DEPLOYMENT SCRIPTS** - `/TOOLS_SCRIPTS_TESTS/scripts/`

### GCP Best Practices
- [Compute Engine Best Practices](https://cloud.google.com/compute/docs/best-practices)
- [Cloud Run Best Practices](https://cloud.google.com/run/docs/best-practices)
- [Cloud SQL Best Practices](https://cloud.google.com/sql/docs/postgres/best-practices)
- [VPC Security Best Practices](https://cloud.google.com/vpc/docs/best-practices)

### Performance Tuning
- [Python Telegram Bot Optimization](https://github.com/python-telegram-bot/python-telegram-bot/wiki/Performance-Optimizations)
- [Flask Production Deployment](https://flask.palletsprojects.com/en/stable/deploying/)
- [Cloud SQL Connection Pooling](https://cloud.google.com/sql/docs/postgres/manage-connections)

---

**END OF DOCUMENT**

Generated: 2025-11-21
Author: Claude Code
Review Status: ‚úÖ Ready for implementation
