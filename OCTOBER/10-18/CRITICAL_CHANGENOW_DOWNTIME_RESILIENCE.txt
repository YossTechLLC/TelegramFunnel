================================================================================
CRITICAL: CHANGENOW EXTENDED DOWNTIME RESILIENCE
Database-First Architecture to Prevent Lost Payouts
TelegramFunnel Payment System - October 2025
================================================================================

⚠️ CRITICAL ISSUE IDENTIFIED ⚠️

This document addresses a CRITICAL architectural oversight in the current
payment flow: if ChangeNow API is down for > 30 minutes, client payouts are
PERMANENTLY LOST with no recovery mechanism.

SEVERITY: CRITICAL
IMPACT: Financial loss for clients (unpaid subscriptions)
LIKELIHOOD: Low but non-zero (ChangeNow outages happen)
CURRENT STATUS: NO automated recovery mechanism exists

================================================================================
TABLE OF CONTENTS
================================================================================

1. Problem Statement
2. Current Architecture Vulnerability Analysis
3. Failure Scenario Walkthrough
4. Financial Impact Assessment
5. Root Cause Analysis
6. Proposed Solution: Database-First (Write-Ahead Log)
7. Alternative Solutions Comparison
8. Recommended Architecture
9. Implementation Requirements
10. Migration Strategy
11. Monitoring & Alerting
12. Cost-Benefit Analysis

================================================================================
1. PROBLEM STATEMENT
================================================================================

THE CRITICAL OVERSIGHT
----------------------

Current payment flow has a RACE CONDITION between:
1. User payment completion (COMMITTED)
2. Channel access grant (COMMITTED)
3. Client payout initiation (NOT COMMITTED if ChangeNow down)

Timeline of vulnerability:

T+0s: User completes payment via NowPayments ✅ COMMITTED
    ↓
T+1s: NowPayments redirects to GCWebhook with success_url ✅ COMMITTED
    ↓
T+2s: GCWebhook decodes token, validates payment ✅ COMMITTED
    ↓
T+3s: GCWebhook grants Telegram channel access ✅ COMMITTED
    ↓ **CRITICAL POINT: User has paid and received access**
    ↓
T+4s: GCWebhook inserts to split_payout_request database ✅ COMMITTED
    ↓
T+5s: GCWebhook creates Cloud Task → GCSplit ✅ COMMITTED
    ↓
T+6s: Cloud Tasks dispatches task to GCSplit
    ↓
T+7s: GCSplit receives task
    ↓
T+8s: GCSplit queries ChangeNow API for exchange rate
    ↓
    ❌ **FAILURE POINT: ChangeNow API is DOWN**
    ↓
T+9s: GCSplit returns HTTP 503 (Service Unavailable)
    ↓
T+14s: Cloud Tasks retry 1 → ChangeNow still down → HTTP 503
    ↓
T+24s: Cloud Tasks retry 2 → ChangeNow still down → HTTP 503
    ↓
T+44s: Cloud Tasks retry 3 → ChangeNow still down → HTTP 503
    ↓
T+84s: Cloud Tasks retry 4 → ChangeNow still down → HTTP 503
    ↓
T+144s: Cloud Tasks retry 5 (FINAL) → ChangeNow still down → HTTP 503
    ↓
T+144s: Cloud Tasks marks task as FAILED (max attempts exceeded)
    ↓
    ❌ **NO ChangeNow transaction created**
    ❌ **NO entry in split_payout_que database**
    ❌ **NO ETH payment to ChangeNow**
    ❌ **NO payout to client**
    ❌ **Task is DEAD - will never retry again**


THE CONSEQUENCE
---------------

State of the system at T+144s (2.4 minutes after payment):

✅ User has paid $25 for subscription
✅ User has been granted channel access (invitation link sent)
✅ Entry exists in split_payout_request table (status: created)
❌ NO entry in split_payout_que (ChangeNow transaction never created)
❌ Client wallet will NEVER receive payout
❌ $23.75 (95% of $25) is LOST to the client
❌ NO automatic recovery mechanism

From user's perspective: Everything worked perfectly ✅
From client's perspective: They got ROBBED (no payout received) ❌


THE FUNDAMENTAL FLAW
--------------------

Current architecture assumes:
- ChangeNow API is always available
- ChangeNow API calls succeed within Cloud Tasks retry window (2-3 minutes)
- If ChangeNow is down, it recovers within 2-3 minutes

Reality:
- ChangeNow API can have extended outages (30 minutes, 1 hour, 4 hours)
- Network issues can last 10-20 minutes
- Maintenance windows can be 1-2 hours
- Cloud Tasks retry window (2-3 minutes) is INSUFFICIENT


THE MISSING PIECE
-----------------

There is NO mechanism to:
- Detect payments that completed but ChangeNow transaction failed
- Automatically retry ChangeNow API calls after Cloud Tasks gives up
- Alert administrators to stuck payments
- Provide manual recovery tools

Once Cloud Tasks marks the task as failed, the payment is ORPHANED.

================================================================================
2. CURRENT ARCHITECTURE VULNERABILITY ANALYSIS
================================================================================

CURRENT FLOW (VULNERABLE)
--------------------------

GCWebhook10-16 receives success_url redirect:
    ↓
[Step 1] Decode and verify token ✅
    ↓
[Step 2] Grant Telegram channel access ✅ COMMITTED
    ↓
[Step 3] Insert to split_payout_request ✅ COMMITTED
    Data:
    - unique_id: "ABC123"
    - subscription_price: 25.00
    - timestamp: 2025-10-25 14:30:00
    - status: "created" (or similar)
    ↓
[Step 4] Create Cloud Task → GCSplit
    Payload: {unique_id: "ABC123", subscription_price: 25.00}
    ↓
    ⚠️ **VULNERABILITY WINDOW BEGINS**
    ↓
GCSplit10-21 receives task:
    ↓
[Step 5] Query ChangeNow API for rate
    ↓ **IF CHANGENOW IS DOWN:**
    ↓   - Returns None
    ↓   - GCSplit returns HTTP 503
    ↓   - Cloud Tasks retries (max 5 attempts)
    ↓   - If all retries fail → Task marked as FAILED
    ↓   - **GAME OVER - No further action**
    ↓
    ❌ NO entry created in split_payout_que
    ❌ NO ChangeNow transaction
    ❌ NO ETH payment
    ❌ NO client payout


WHAT SHOULD HAPPEN VS WHAT ACTUALLY HAPPENS
--------------------------------------------

Scenario: ChangeNow API down for 45 minutes

What SHOULD happen:
1. User pays → ✅ Success
2. User granted access → ✅ Success
3. ChangeNow API called → ❌ Fails (API down)
4. System retries for 45 minutes → ✅ ChangeNow comes back online
5. ChangeNow transaction created → ✅ Success (eventually)
6. Client receives payout → ✅ Success (delayed but delivered)

What ACTUALLY happens:
1. User pays → ✅ Success
2. User granted access → ✅ Success
3. ChangeNow API called → ❌ Fails (API down)
4. Cloud Tasks retries for 2-3 minutes → ❌ All fail
5. Task marked as failed → ❌ DEAD TASK
6. Client payout NEVER happens → ❌ LOST FOREVER


DATABASE STATE ANALYSIS
------------------------

After failed ChangeNow attempt:

Table: split_payout_request
unique_id  | subscription_price | timestamp           | status
-----------|-------------------|---------------------|--------
ABC123     | 25.00             | 2025-10-25 14:30:00 | created

Table: split_payout_que
(EMPTY - no record exists)

Table: split_payout_hostpay
(EMPTY - no record exists)

⚠️ CRITICAL OBSERVATION:
The payment exists in split_payout_request, but has NO corresponding
entry in split_payout_que. This is an ORPHANED payment.

There is NO database query that can find:
"Show me payments that completed but ChangeNow transaction failed"

Why? Because there's no status field to indicate "ChangeNow pending".


CLOUD TASKS RETRY LIMITATIONS
------------------------------

Current split-payment-queue configuration:
- max_attempts: 5
- min_backoff: 1s
- max_backoff: 60s
- max_doublings: 5

Retry timeline:
- Attempt 1: T+0s
- Retry 1: T+1s (backoff: 1s)
- Retry 2: T+3s (backoff: 2s)
- Retry 3: T+7s (backoff: 4s)
- Retry 4: T+15s (backoff: 8s)
- Retry 5: T+31s (backoff: 16s)
- ... continues with 60s max backoff ...
- Final retry: ~T+144s (2.4 minutes)

After T+144s: Task marked as FAILED, no further retries

⚠️ PROBLEM: ChangeNow outages can last MUCH longer than 2-3 minutes

Real-world ChangeNow outage examples (hypothetical but realistic):
- Deployment/maintenance: 30-60 minutes
- Infrastructure failure: 2-4 hours
- Network issues: 10-30 minutes
- API rate limiting spike: 5-15 minutes

Cloud Tasks retry window is INADEQUATE for real-world outages.


NO RECOVERY MECHANISM
----------------------

Once Cloud Tasks marks task as failed, there is:

❌ No automatic retry mechanism
❌ No alert to administrators
❌ No database flag indicating "stuck" payment
❌ No cron job to check for orphaned payments
❌ No manual recovery tool
❌ No way to even DETECT the problem

The payment is SILENTLY LOST.

Client will never know their payout failed until they check their wallet
and realize they didn't receive payment (could be days/weeks later).

================================================================================
3. FAILURE SCENARIO WALKTHROUGH
================================================================================

SCENARIO 1: CHANGENOW MAINTENANCE WINDOW (1 HOUR)
--------------------------------------------------

Timeline:

2025-10-25 14:00:00 - ChangeNow begins maintenance (API returns 503)

2025-10-25 14:15:00 - User completes payment
    ↓
2025-10-25 14:15:01 - GCWebhook grants channel access ✅
    ↓
2025-10-25 14:15:02 - GCWebhook creates Cloud Task
    ↓
2025-10-25 14:15:03 - GCSplit attempts ChangeNow API → 503 (maintenance)
    ↓
2025-10-25 14:15:05 - Cloud Tasks retry 1 → 503
2025-10-25 14:15:09 - Cloud Tasks retry 2 → 503
2025-10-25 14:15:17 - Cloud Tasks retry 3 → 503
2025-10-25 14:15:33 - Cloud Tasks retry 4 → 503
2025-10-25 14:16:33 - Cloud Tasks retry 5 → 503
    ↓
2025-10-25 14:17:33 - Cloud Tasks marks task as FAILED ❌
    ↓
    **PAYMENT ORPHANED**
    ↓
2025-10-25 15:00:00 - ChangeNow maintenance complete (API back online)
    ↓
    **BUT: Task already failed 43 minutes ago**
    **NO automatic retry will happen**
    **Client payout LOST**


User's experience:
- Paid $25 ✅
- Got channel access ✅
- Happy customer ✅

Client's experience:
- Subscription sold ✅
- Expected $23.75 payout ❌
- Never received payment ❌
- No notification of failure ❌
- Angry client ❌


SCENARIO 2: INTERMITTENT CHANGENOW API ISSUES (30 MINUTES)
-----------------------------------------------------------

Timeline:

2025-10-25 10:00:00 - ChangeNow API starts experiencing issues
    - 50% of requests succeed
    - 50% of requests timeout or return 503

2025-10-25 10:10:00 - User completes payment
    ↓
2025-10-25 10:10:01 - GCWebhook grants access ✅
    ↓
2025-10-25 10:10:02 - GCSplit attempts rate query → TIMEOUT (30s)
    ↓
2025-10-25 10:10:32 - GCSplit returns HTTP 503
    ↓
2025-10-25 10:10:37 - Cloud Tasks retry 1 → rate query succeeds! ✅
    ↓
2025-10-25 10:10:40 - GCSplit attempts transaction creation → TIMEOUT (30s)
    ↓
2025-10-25 10:11:10 - GCSplit returns HTTP 503
    ↓
2025-10-25 10:11:15 - Cloud Tasks retry 2 → transaction succeeds! ✅
    ↓
2025-10-25 10:11:20 - Client payout initiated ✅

Result: Payment succeeded (eventually) after 1 minute 20 seconds

⚠️ OBSERVATION: Cloud Tasks retry DID work in this case because issues
resolved within the 2-3 minute retry window.


SCENARIO 3: CHANGENOW COMPLETELY DOWN (4 HOURS)
------------------------------------------------

Timeline:

2025-10-25 08:00:00 - ChangeNow infrastructure failure (complete outage)

2025-10-25 09:30:00 - User completes payment
    ↓
2025-10-25 09:30:03 - GCSplit attempts ChangeNow API → Connection refused
    ↓
2025-10-25 09:32:00 - All Cloud Tasks retries exhausted → FAILED ❌
    ↓
    **PAYMENT ORPHANED**
    ↓
2025-10-25 12:00:00 - ChangeNow infrastructure restored (API back online)
    ↓
    **BUT: Task failed 2.5 hours ago**
    **Client payout LOST**


SCENARIO 4: MULTIPLE PAYMENTS DURING OUTAGE (CASCADING FAILURES)
-----------------------------------------------------------------

Timeline:

2025-10-25 16:00:00 - ChangeNow API rate limiting (429 responses)

During next 10 minutes, 20 users complete payments:

2025-10-25 16:01:00 - User 1 pays → ChangeNow fails → Task failed
2025-10-25 16:02:00 - User 2 pays → ChangeNow fails → Task failed
2025-10-25 16:03:00 - User 3 pays → ChangeNow fails → Task failed
...
2025-10-25 16:10:00 - User 20 pays → ChangeNow fails → Task failed

Result:
- 20 users happy (got channel access) ✅
- 20 clients NOT paid (lost $475 total) ❌
- NO alerts, NO notifications, NO recovery ❌


FINANCIAL IMPACT OF SCENARIOS
------------------------------

Scenario 1 (1 hour outage):
- Users affected: ~10 (assuming 10 payments/hour)
- Average payment: $25
- Client loss: $237.50 (10 × $23.75)

Scenario 3 (4 hour outage):
- Users affected: ~40
- Average payment: $25
- Client loss: $950 (40 × $23.75)

Scenario 4 (10 minute rate limit spike):
- Users affected: 20
- Client loss: $475

**Annual risk (assuming 1 major outage/month):**
$950 × 12 months = $11,400 lost to clients per year

This is UNACCEPTABLE.

================================================================================
4. FINANCIAL IMPACT ASSESSMENT
================================================================================

QUANTIFYING THE RISK
--------------------

Assumptions:
- Average payment: $25
- Client payout: 95% = $23.75
- Payment volume: 1,000/month
- ChangeNow uptime: 99.9% (industry standard)
- ChangeNow extended outages (> 3 min): 1-2 per month

Expected monthly failures:
- 1,000 payments × 0.1% failure rate = 1 payment/month (base)
- 1-2 extended outages/month × 10 payments during outage = 10-20 payments/month (extended)
- Total at-risk: 11-21 payments/month

Monthly financial impact:
- 11-21 payments × $23.75 = $261 - $499 per month
- Annual impact: $3,132 - $5,988 per year

**Conservative estimate: $4,000/year lost to clients**


REPUTATIONAL IMPACT
-------------------

Beyond direct financial loss:

1. Client Trust Erosion
   - Clients expect payouts to match subscriptions
   - Missing payouts damage trust
   - May lose clients entirely

2. Support Overhead
   - Clients open support tickets
   - Manual investigation required
   - Manual payout processing
   - Estimated: 2 hours per incident × $50/hour = $100/incident

3. Manual Recovery Cost
   - Identify orphaned payments (database query)
   - Manually create ChangeNow transactions
   - Verify payouts completed
   - Update database records
   - Estimated: 30 minutes per payment × $50/hour = $25/payment

Annual support cost:
- 120-240 incidents/year × $100 = $12,000 - $24,000
- Recovery cost: 120-240 × $25 = $3,000 - $6,000
- Total operational cost: $15,000 - $30,000/year

**Combined annual impact:**
- Direct loss: $4,000
- Operational cost: $15,000 - $30,000
- Total: $19,000 - $34,000/year

This justifies IMMEDIATE implementation of automated recovery.


PROBABILITY ASSESSMENT
----------------------

P(ChangeNow outage > 3 minutes) = ?

Historical data (typical SaaS API):
- 99.9% uptime = 43 minutes downtime/month
- Outages are not evenly distributed
- 1-2 significant outages/month (10-30 minutes each)
- Many micro-outages (< 1 minute)

P(payment occurs during outage) = ?
- If outage is 30 minutes: 30/1440 = 2% of daily traffic
- If 20 payments/day: 0.4 payments affected per 30-min outage
- If 2 outages/month: ~1 payment affected/month (minimum)

But with Cloud Tasks retry window (2-3 minutes):
- Only outages > 3 minutes cause permanent failure
- P(outage > 3 minutes) = ~50% of all outages
- Expected: 1 significant outage/month affects 5-10 payments

**Conservative estimate: 10 orphaned payments/month**

This aligns with financial impact calculations above.


RISK SEVERITY MATRIX
--------------------

Risk Factor              | Severity | Likelihood | Priority
-------------------------|----------|------------|----------
Financial loss to client | HIGH     | MEDIUM     | CRITICAL
Reputational damage      | HIGH     | MEDIUM     | CRITICAL
Support overhead         | MEDIUM   | HIGH       | HIGH
Manual recovery effort   | MEDIUM   | HIGH       | HIGH
No detection mechanism   | CRITICAL | CERTAIN    | CRITICAL
No automated recovery    | CRITICAL | CERTAIN    | CRITICAL

OVERALL RISK RATING: **CRITICAL**

Recommendation: IMMEDIATE implementation of recovery mechanism required.

================================================================================
5. ROOT CAUSE ANALYSIS
================================================================================

WHY DOES THIS PROBLEM EXIST?
-----------------------------

Root Cause 1: Architecture Assumes Happy Path
----------------------------------------------

Current design optimizes for:
✅ Fast payment processing (< 10 seconds)
✅ Low latency (async Cloud Tasks)
✅ Simple flow (minimal steps)

But does NOT handle:
❌ Extended external API failures
❌ Orphaned transactions
❌ Recovery from task failures

This is a classic "optimistic locking" pattern without pessimistic fallback.


Root Cause 2: Missing Write-Ahead Log Pattern
----------------------------------------------

Payment systems should follow Write-Ahead Log (WAL) pattern:
1. Write intent to durable storage (database)
2. Perform external operations (API calls)
3. Update status based on results
4. Background worker ensures eventual consistency

Current system does NOT follow this pattern:
1. External operation attempted (ChangeNow API) ❌ NOT DURABLE
2. If operation succeeds → write to database ❌ WRONG ORDER
3. If operation fails → nothing written ❌ LOST STATE


Root Cause 3: Cloud Tasks is Task-Oriented, Not State-Oriented
---------------------------------------------------------------

Cloud Tasks guarantees:
✅ At-least-once delivery (within retry window)
✅ Automatic retry on transient failures
✅ Rate limiting and queue management

Cloud Tasks does NOT guarantee:
❌ Infinite retries (max_attempts limit)
❌ Persistence beyond retry window (tasks expire)
❌ State recovery after task failure

Cloud Tasks is for EPHEMERAL workflows, not PERSISTENT state management.

For financial transactions (persistent state), need database-backed recovery.


Root Cause 4: No Reconciliation Process
----------------------------------------

Payment systems need reconciliation:
- Daily/hourly: Check for inconsistencies
- Compare payment gateway records vs payout records
- Identify orphaned/stuck transactions
- Automatically or manually recover

Current system has:
❌ No reconciliation job
❌ No consistency checks
❌ No alerting for stuck payments


Root Cause 5: Status Field Not Used Properly
---------------------------------------------

split_payout_request table has limited status tracking:
- Status: "created" (or similar)
- Does not track: "pending_changenow", "changenow_failed", "changenow_completed"

Without granular status, cannot query for:
"Show me payments where ChangeNow transaction not yet initiated"


CONTRIBUTING FACTORS
--------------------

Factor 1: ChangeNow is Third-Party Dependency
- Outside our control
- Unpredictable availability
- Cannot assume 100% uptime

Factor 2: Time Gap Between Payment and Payout
- User pays immediately
- Payout happens seconds/minutes later
- Window for failures to occur

Factor 3: No End-to-End Transaction
- User payment, channel access, and client payout are SEPARATE transactions
- No database transaction spans all three
- Inconsistency is possible

Factor 4: Monitoring Gaps
- No alerting for failed Cloud Tasks
- No dashboard showing orphaned payments
- Reactive (wait for client to complain) vs proactive (detect and fix)


THE FUNDAMENTAL DESIGN FLAW
----------------------------

Current architecture treats client payout as:
"Nice to have, we'll try to do it"

Should be:
"MUST happen, guaranteed eventual delivery"

Payment processing is a TWO-PHASE COMMIT problem:
1. User pays → Channel access granted (Phase 1)
2. Client payout MUST be guaranteed (Phase 2)

Currently, Phase 2 is NOT guaranteed.

================================================================================
6. PROPOSED SOLUTION: DATABASE-FIRST (WRITE-AHEAD LOG)
================================================================================

ARCHITECTURAL PRINCIPLE: WRITE-AHEAD LOG (WAL)
-----------------------------------------------

Key principle from database systems:
"Write the intent to durable storage BEFORE attempting the operation"

Applied to payment flow:
1. User pays
2. WRITE to database: "This payment needs a payout" (DURABLE INTENT)
3. ATTEMPT ChangeNow API calls
4. UPDATE database: Success or failure status
5. If failed: Background worker retries (EVENTUAL CONSISTENCY)


PROPOSED FLOW (RESILIENT)
--------------------------

GCWebhook10-16 receives success_url redirect:
    ↓
[Step 1] Decode and verify token ✅
    ↓
[Step 2] Grant Telegram channel access ✅ COMMITTED
    ↓
[Step 3] ⭐ INSERT to split_payout_request (ENHANCED) ⭐
    Data:
    - unique_id: "ABC123"
    - user_id: 123456
    - subscription_price: 25.00
    - open_channel_id: "-1001234567890"
    - closed_channel_id: "-1001234567891"
    - client_wallet_address: "0xABCD..."
    - client_payout_currency: "USDT"
    - client_payout_network: "bsc"
    - status: "pending_changenow" ⭐ KEY FIELD
    - created_at: 2025-10-25 14:30:00
    - updated_at: 2025-10-25 14:30:00
    - retry_count: 0
    - last_error: NULL
    ↓
    ⭐ CRITICAL: ALL payout data now in database BEFORE ChangeNow call
    ↓
[Step 4] Create Cloud Task → GCSplit
    ↓
    ✅ Even if Cloud Tasks fails, database record exists for recovery
    ↓
GCSplit10-21 receives task:
    ↓
[Step 5] Query ChangeNow API for rate
    ↓ IF SUCCESS:
    ↓   Continue to transaction creation
    ↓ IF FAILURE:
    ↓   Update split_payout_request: status="changenow_failed", last_error="Rate query timeout"
    ↓   Return HTTP 503 (Cloud Tasks will retry)
    ↓
[Step 6] Create ChangeNow transaction
    ↓ IF SUCCESS:
    ↓   Insert to split_payout_que
    ↓   Update split_payout_request: status="changenow_completed"
    ↓   Create HostPay task
    ↓ IF FAILURE:
    ↓   Update split_payout_request: status="changenow_failed", last_error="Transaction creation failed"
    ↓   Return HTTP 503
    ↓
[Step 7] ⭐ BACKGROUND RECOVERY JOB (Cloud Scheduler) ⭐
    ↓
    Runs every 5 minutes
    ↓
    Query: SELECT * FROM split_payout_request
           WHERE status IN ('pending_changenow', 'changenow_failed')
           AND created_at < NOW() - INTERVAL 5 MINUTE
           AND retry_count < 100
    ↓
    For each orphaned payment:
        ↓ Retry ChangeNow API calls
        ↓ Update status based on result
        ↓ Increment retry_count
        ↓
        IF successful:
            ↓ Create HostPay task
            ↓ Update status: "changenow_completed"
        ↓
        IF failed but retryable:
            ↓ Update status: "changenow_failed"
            ↓ Will retry again in 5 minutes
        ↓
        IF failed permanently (retry_count > 100):
            ↓ Update status: "changenow_permanent_failure"
            ↓ Send alert to admin
            ↓ Requires manual intervention


KEY IMPROVEMENTS
----------------

✅ **Database-First**: All payout data saved BEFORE ChangeNow call
✅ **Status Tracking**: Granular status shows exactly where payment is stuck
✅ **Automatic Recovery**: Background job retries indefinitely (up to limit)
✅ **No Lost Payments**: Even if Cloud Tasks fails, database record exists
✅ **ChangeNow Downtime Resilient**: Can be down for hours/days, will eventually retry
✅ **Monitoring Friendly**: Query database to see stuck payments
✅ **Manual Recovery Possible**: Admin can see and fix stuck payments
✅ **Audit Trail**: retry_count and last_error show what happened


ENHANCED DATABASE SCHEMA
-------------------------

Table: split_payout_request (ENHANCED)

CREATE TABLE split_payout_request (
    unique_id VARCHAR(16) PRIMARY KEY,
    user_id BIGINT NOT NULL,
    subscription_price DECIMAL(10,2) NOT NULL,
    open_channel_id VARCHAR(50) NOT NULL,
    closed_channel_id VARCHAR(50) NOT NULL,

    -- ⭐ NEW: Client payout information (needed for ChangeNow)
    client_wallet_address VARCHAR(110),
    client_payout_currency VARCHAR(4),
    client_payout_network VARCHAR(10),

    -- ⭐ NEW: Status tracking for recovery
    status ENUM(
        'pending_changenow',      -- Waiting for ChangeNow API call
        'changenow_processing',   -- ChangeNow API in progress
        'changenow_completed',    -- ChangeNow transaction created
        'changenow_failed',       -- ChangeNow API failed (will retry)
        'changenow_permanent_failure'  -- Max retries exceeded (manual intervention)
    ) NOT NULL DEFAULT 'pending_changenow',

    -- ⭐ NEW: Retry tracking
    retry_count INT NOT NULL DEFAULT 0,
    last_retry_at DATETIME,
    last_error TEXT,

    -- Timestamps
    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    -- Indexes for recovery queries
    INDEX idx_status_created (status, created_at),
    INDEX idx_retry_count (retry_count)
);


BACKGROUND RECOVERY JOB LOGIC
------------------------------

Cloud Scheduler configuration:
- Schedule: */5 * * * * (every 5 minutes)
- Target: Cloud Run service (new endpoint: /recover_orphaned_payments)
- Timeout: 540 seconds (9 minutes - leave 1 min buffer)

Pseudo-code:

```python
def recover_orphaned_payments():
    """
    Background job to recover payments where ChangeNow API failed.
    Runs every 5 minutes via Cloud Scheduler.
    """

    # Find payments stuck in pending/failed state
    orphaned_payments = db.query("""
        SELECT * FROM split_payout_request
        WHERE status IN ('pending_changenow', 'changenow_failed')
        AND created_at < NOW() - INTERVAL 5 MINUTE
        AND retry_count < 100
        ORDER BY created_at ASC
        LIMIT 100
    """)

    print(f"🔍 [RECOVERY] Found {len(orphaned_payments)} orphaned payments")

    for payment in orphaned_payments:
        try:
            print(f"🔄 [RECOVERY] Retrying payment {payment.unique_id} (attempt {payment.retry_count + 1})")

            # Attempt ChangeNow API calls
            rate = get_changenow_rate(
                from_currency="usd",
                to_currency=payment.client_payout_currency,
                amount=payment.subscription_price * 0.95
            )

            if rate is None:
                # ChangeNow still down - update and try again later
                db.execute("""
                    UPDATE split_payout_request
                    SET status = 'changenow_failed',
                        retry_count = retry_count + 1,
                        last_retry_at = NOW(),
                        last_error = 'ChangeNow rate API unavailable'
                    WHERE unique_id = ?
                """, payment.unique_id)
                print(f"⚠️ [RECOVERY] Rate query failed for {payment.unique_id}, will retry later")
                continue

            # Create ChangeNow transaction
            transaction = create_changenow_transaction(
                from_currency="usd",
                to_currency=payment.client_payout_currency,
                to_network=payment.client_payout_network,
                address=payment.client_wallet_address,
                amount=payment.subscription_price * 0.95
            )

            if transaction is None:
                # Transaction creation failed
                db.execute("""
                    UPDATE split_payout_request
                    SET status = 'changenow_failed',
                        retry_count = retry_count + 1,
                        last_retry_at = NOW(),
                        last_error = 'ChangeNow transaction creation failed'
                    WHERE unique_id = ?
                """, payment.unique_id)
                print(f"⚠️ [RECOVERY] Transaction creation failed for {payment.unique_id}")
                continue

            # SUCCESS! Insert to split_payout_que
            db.execute("""
                INSERT INTO split_payout_que (
                    unique_id, cn_api_id, from_currency, to_currency, ...
                ) VALUES (?, ?, ?, ?, ...)
            """, payment.unique_id, transaction.id, ...)

            # Update status
            db.execute("""
                UPDATE split_payout_request
                SET status = 'changenow_completed',
                    retry_count = retry_count + 1,
                    last_retry_at = NOW(),
                    last_error = NULL
                WHERE unique_id = ?
            """, payment.unique_id)

            # Create HostPay task
            create_hostpay_task(transaction_id=transaction.id, ...)

            print(f"✅ [RECOVERY] Successfully recovered payment {payment.unique_id}")

        except Exception as e:
            print(f"❌ [RECOVERY] Unexpected error for {payment.unique_id}: {e}")
            db.execute("""
                UPDATE split_payout_request
                SET retry_count = retry_count + 1,
                    last_retry_at = NOW(),
                    last_error = ?
                WHERE unique_id = ?
            """, str(e), payment.unique_id)

    # Check for payments that exceeded max retries
    permanent_failures = db.query("""
        SELECT * FROM split_payout_request
        WHERE status = 'changenow_failed'
        AND retry_count >= 100
        AND created_at > NOW() - INTERVAL 7 DAY
    """)

    if permanent_failures:
        print(f"🚨 [RECOVERY] Found {len(permanent_failures)} payments with permanent failures")
        for payment in permanent_failures:
            db.execute("""
                UPDATE split_payout_request
                SET status = 'changenow_permanent_failure'
                WHERE unique_id = ?
            """, payment.unique_id)

            # Send alert to admin
            send_admin_alert(
                subject=f"Payment {payment.unique_id} requires manual intervention",
                body=f"Payment has failed after 100 retry attempts. Last error: {payment.last_error}"
            )
```


RECOVERY TIMELINE EXAMPLE
--------------------------

Scenario: ChangeNow down for 1 hour

2025-10-25 14:00:00 - ChangeNow maintenance begins

2025-10-25 14:15:00 - User pays
    ↓ GCWebhook grants access ✅
    ↓ GCWebhook inserts to split_payout_request (status: "pending_changenow") ✅
    ↓ GCWebhook creates Cloud Task ✅
    ↓
2025-10-25 14:15:03 - GCSplit attempts ChangeNow → Fails
    ↓ Updates status to "changenow_failed"
    ↓ Cloud Tasks retries for 2 minutes
    ↓ All retries fail
    ↓
2025-10-25 14:17:00 - Cloud Tasks marks task as FAILED
    ↓ **BUT: Database record still exists with status="changenow_failed"**
    ↓
2025-10-25 14:20:00 - Background recovery job runs (1st attempt)
    ↓ Finds payment with status="changenow_failed"
    ↓ Attempts ChangeNow API → Still down, fails
    ↓ Updates retry_count = 1
    ↓
2025-10-25 14:25:00 - Recovery job runs (2nd attempt)
    ↓ Attempts ChangeNow API → Still down, fails
    ↓ retry_count = 2
    ↓
... continues every 5 minutes ...
    ↓
2025-10-25 15:00:00 - ChangeNow maintenance complete
    ↓
2025-10-25 15:00:00 - Recovery job runs (9th attempt)
    ↓ Attempts ChangeNow API → SUCCESS! ✅
    ↓ Creates ChangeNow transaction
    ↓ Inserts to split_payout_que
    ↓ Creates HostPay task
    ↓ Updates status to "changenow_completed"
    ↓
2025-10-25 15:01:00 - Client receives payout ✅

**Total time from payment to payout: 46 minutes**
**Result: SUCCESS (delayed but delivered)**

Without recovery mechanism:
- Payment would be LOST after 2 minutes ❌

================================================================================
7. ALTERNATIVE SOLUTIONS COMPARISON
================================================================================

SOLUTION 1: DATABASE-FIRST (WRITE-AHEAD LOG) ⭐ RECOMMENDED
------------------------------------------------------------

Approach: Save ALL payout data to database BEFORE calling ChangeNow,
          background job ensures eventual delivery

Pros:
✅ Guarantees eventual delivery (no lost payments)
✅ ChangeNow can be down for hours/days - will still recover
✅ Simple to implement (database changes + cron job)
✅ Easy to monitor (query database for stuck payments)
✅ Manual recovery possible (admin can fix stuck payments)
✅ Audit trail (status, retry_count, last_error)
✅ Works with existing Cloud Tasks architecture

Cons:
❌ Adds database writes (minimal cost)
❌ Requires background job (Cloud Scheduler cost: ~$0.10/month)
❌ Slightly more complex database schema

Effort: MEDIUM (1-2 weeks)
Cost: LOW ($0.10/month for Cloud Scheduler)
Risk: LOW (non-breaking change, incremental improvement)

VERDICT: ✅ **STRONGLY RECOMMENDED**


SOLUTION 2: EXTENDED CLOUD TASKS RETRY WINDOW
----------------------------------------------

Approach: Increase Cloud Tasks max_attempts and max_backoff to extend
          retry window from 3 minutes to 30-60 minutes

Configuration:
```bash
gcloud tasks queues update split-payment-queue \
    --max-attempts=20 \
    --max-backoff=600s \
    --min-backoff=10s
```

Retry timeline:
- Attempt 1-10: Backoff increases from 10s to 600s
- Total retry window: ~60 minutes

Pros:
✅ Simple to implement (configuration change only)
✅ No code changes required
✅ Handles outages up to 1 hour
✅ No additional infrastructure

Cons:
❌ Still has max limit (what if ChangeNow down > 1 hour?)
❌ No recovery after max_attempts exceeded
❌ Keeps Cloud Run instances busy during retries (cost)
❌ No visibility into stuck payments
❌ No manual recovery option

Effort: MINIMAL (5 minutes)
Cost: MEDIUM (longer Cloud Run execution times)
Risk: LOW

VERDICT: ⚠️ **Partial solution, not sufficient alone**


SOLUTION 3: DEAD LETTER QUEUE + MANUAL PROCESSING
--------------------------------------------------

Approach: Configure Cloud Tasks dead letter queue, admin manually processes
          failed tasks

Configuration:
```bash
gcloud tasks queues update split-payment-queue \
    --max-attempts=5 \
    --dead-letter-queue=projects/PROJECT/locations/LOCATION/queues/dlq-split-payment
```

Pros:
✅ Failed tasks preserved (not lost)
✅ Admin can inspect and manually retry
✅ Simple to configure

Cons:
❌ Requires MANUAL intervention (not automatic)
❌ Admin must monitor dead letter queue daily
❌ Slow recovery (depends on admin availability)
❌ Doesn't scale (what if 100 failed tasks?)
❌ No automatic retry mechanism

Effort: MINIMAL (10 minutes)
Cost: LOW
Risk: LOW

VERDICT: ⚠️ **Better than nothing, but not automatic**


SOLUTION 4: DUAL CLOUD TASKS QUEUES (FAST + SLOW)
--------------------------------------------------

Approach: Create two queues - fast retry (3 minutes) and slow retry (hours)
          If fast queue fails, create task in slow queue

Queues:
- split-payment-queue-fast: max_attempts=5, max_backoff=60s
- split-payment-queue-slow: max_attempts=50, max_backoff=3600s

Logic:
```python
# GCWebhook creates task in fast queue
create_task(queue="split-payment-queue-fast", ...)

# GCSplit, on failure after max retries:
if attempt_count >= 5:
    # Create task in slow queue for long-term retry
    create_task(queue="split-payment-queue-slow", ...)
```

Pros:
✅ Fast recovery for transient failures
✅ Long-term retry for extended outages
✅ Automatic (no manual intervention)

Cons:
❌ Complex logic (when to switch queues?)
❌ Duplicate task creation (fast + slow)
❌ Still has max limit (what if slow queue exhausted?)
❌ No database state tracking

Effort: HIGH (significant code changes)
Cost: LOW
Risk: MEDIUM (complexity)

VERDICT: ⚠️ **Overly complex, database-first is simpler**


SOLUTION 5: HYBRID (DATABASE-FIRST + EXTENDED RETRY)
-----------------------------------------------------

Approach: Combine Solution 1 (database-first) with Solution 2 (extended retry)

Implementation:
1. Save all data to database (status: "pending_changenow")
2. Cloud Tasks retries with extended window (30 minutes)
3. Background job recovers anything Cloud Tasks missed

Pros:
✅ Best of both worlds
✅ Fast recovery for most failures (Cloud Tasks)
✅ Guaranteed recovery for all failures (background job)
✅ Minimal background job work (only runs for persistent failures)

Cons:
❌ Slightly more complex than database-first alone
❌ Two recovery mechanisms (could be confusing)

Effort: MEDIUM (same as database-first)
Cost: LOW
Risk: LOW

VERDICT: ✅ **EXCELLENT - Recommended for production**


COMPARISON MATRIX
-----------------

Solution                    | Reliability | Complexity | Cost | Effort | Score
----------------------------|-------------|------------|------|--------|------
1. Database-First (WAL)     | ⭐⭐⭐⭐⭐ | ⭐⭐⭐   | ⭐⭐ | ⭐⭐⭐ | 13/15
2. Extended Retry Window    | ⭐⭐⭐     | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 12/15
3. Dead Letter Queue        | ⭐⭐       | ⭐⭐⭐⭐   | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 11/15
4. Dual Queues              | ⭐⭐⭐⭐   | ⭐         | ⭐⭐⭐ | ⭐    | 8/15
5. Hybrid (1 + 2)           | ⭐⭐⭐⭐⭐ | ⭐⭐       | ⭐⭐ | ⭐⭐⭐ | 12/15

WINNER: Solution 1 (Database-First) or Solution 5 (Hybrid)

================================================================================
8. RECOMMENDED ARCHITECTURE
================================================================================

FINAL RECOMMENDED SOLUTION: HYBRID APPROACH
--------------------------------------------

Combine database-first pattern with extended Cloud Tasks retry for
maximum reliability with minimal complexity.


ARCHITECTURE DIAGRAM
--------------------

User Payment → NowPayments → Success
    ↓
GCWebhook10-16:
    ├─ Grant channel access ✅
    ├─ Insert split_payout_request (status: "pending_changenow", ALL data) ✅
    └─ Create Cloud Task → split-payment-queue
            ↓
        Cloud Tasks (EXTENDED RETRY):
        max_attempts: 10
        max_backoff: 300s (5 minutes)
        Retry window: ~30 minutes
            ↓
        GCSplit10-21:
            ├─ Query ChangeNow rate
            ├─ Create ChangeNow transaction
            ├─ IF SUCCESS:
            │   ├─ Insert split_payout_que
            │   ├─ Update split_payout_request (status: "changenow_completed")
            │   └─ Create HostPay task ✅
            └─ IF FAILURE:
                ├─ Update split_payout_request (status: "changenow_failed", retry_count++)
                └─ Return HTTP 503 (Cloud Tasks retries)
                    ↓
                    ⏰ After 30 minutes of retries...
                    ↓
                    IF still failed: Cloud Tasks gives up
                    ↓
                    Database record still exists (status: "changenow_failed")
                    ↓
                    ⭐ Background Recovery Job (Cloud Scheduler):
                    Runs every 5 minutes
                        ├─ Query: SELECT * FROM split_payout_request
                        │         WHERE status IN ('pending_changenow', 'changenow_failed')
                        │         AND created_at < NOW() - INTERVAL 5 MINUTE
                        ├─ For each orphaned payment:
                        │   ├─ Retry ChangeNow API
                        │   ├─ IF SUCCESS: Create HostPay task ✅
                        │   └─ IF FAIL: Increment retry_count, try again in 5 min
                        └─ Alert admin if retry_count > 100


THREE LAYERS OF RESILIENCE
---------------------------

Layer 1: Cloud Tasks Fast Retry (0-3 minutes)
----------------------------------------------
- Handles 90% of transient failures
- Fast recovery (< 3 minutes)
- No additional cost
- Existing architecture

Layer 2: Cloud Tasks Extended Retry (3-30 minutes)
---------------------------------------------------
- Handles 8% of extended failures
- Moderate recovery (3-30 minutes)
- Minimal additional cost (longer execution times)
- Configuration change only

Layer 3: Background Job Recovery (30 minutes - indefinite)
-----------------------------------------------------------
- Handles 2% of persistent failures
- Eventual recovery (guaranteed)
- Low cost (Cloud Scheduler + periodic execution)
- New infrastructure (Cloud Scheduler + recovery endpoint)

Combined: 100% reliability, no lost payments ✅


IMPLEMENTATION COMPONENTS
--------------------------

Component 1: Enhanced Database Schema
--------------------------------------
File: Database migration script
Changes:
- Add fields to split_payout_request:
  - client_wallet_address VARCHAR(110)
  - client_payout_currency VARCHAR(4)
  - client_payout_network VARCHAR(10)
  - status ENUM (with new values)
  - retry_count INT
  - last_retry_at DATETIME
  - last_error TEXT
- Add indexes for recovery queries

Component 2: GCWebhook Changes
-------------------------------
File: GCWebhook10-16/tph10-16.py
Changes:
- Modify split_payout_request insert to include:
  - client_wallet_address (from decoded token)
  - client_payout_currency (from decoded token)
  - client_payout_network (from decoded token)
  - status = "pending_changenow"
  - retry_count = 0

Component 3: GCSplit Changes
-----------------------------
File: GCSplit10-21/tps10-21.py
Changes:
- On ChangeNow rate query failure:
  - Update split_payout_request: status="changenow_failed", retry_count++, last_error="..."
- On ChangeNow transaction creation success:
  - Update split_payout_request: status="changenow_completed"
- On ChangeNow transaction creation failure:
  - Update split_payout_request: status="changenow_failed", retry_count++, last_error="..."

Component 4: Extended Cloud Tasks Configuration
------------------------------------------------
Command:
```bash
gcloud tasks queues update split-payment-queue \
    --location=us-central1 \
    --max-attempts=10 \
    --min-backoff=5s \
    --max-backoff=300s \
    --max-doublings=6
```

Component 5: Recovery Job Service
----------------------------------
File: NEW SERVICE - GCRecovery10-21/recovery.py
Endpoint: POST /recover_orphaned_payments
Logic: (See pseudo-code in Section 6)

Component 6: Cloud Scheduler
-----------------------------
Configuration:
```bash
gcloud scheduler jobs create http recover-orphaned-payments \
    --schedule="*/5 * * * *" \
    --uri="https://gcrecovery10-21-xxx.run.app/recover_orphaned_payments" \
    --http-method=POST \
    --oidc-service-account-email=gcrecovery-sa@PROJECT.iam.gserviceaccount.com
```

Component 7: Monitoring Dashboard
----------------------------------
Metrics to track:
- Payments in "pending_changenow" status (should be 0 most of the time)
- Payments in "changenow_failed" status (should be < 5)
- Average retry_count (should be < 2)
- Recovery job success rate (should be > 95%)

Component 8: Alerting
----------------------
Alerts:
- ⚠️ Warning: > 10 payments stuck in "changenow_failed" for > 1 hour
- 🚨 Critical: > 1 payment with status="changenow_permanent_failure"
- 🚨 Critical: Recovery job failed to run (missed 2+ scheduled runs)

================================================================================
9. IMPLEMENTATION REQUIREMENTS
================================================================================

PHASE 1: DATABASE SCHEMA UPDATE (Week 1, Days 1-2)
---------------------------------------------------

Step 1: Write Migration Script
-------------------------------
File: migrations/add_changenow_recovery_fields.sql

```sql
-- Add new fields to split_payout_request
ALTER TABLE split_payout_request
ADD COLUMN client_wallet_address VARCHAR(110) AFTER subscription_price,
ADD COLUMN client_payout_currency VARCHAR(4) AFTER client_wallet_address,
ADD COLUMN client_payout_network VARCHAR(10) AFTER client_payout_currency,
ADD COLUMN status ENUM(
    'pending_changenow',
    'changenow_processing',
    'changenow_completed',
    'changenow_failed',
    'changenow_permanent_failure'
) NOT NULL DEFAULT 'pending_changenow' AFTER client_payout_network,
ADD COLUMN retry_count INT NOT NULL DEFAULT 0 AFTER status,
ADD COLUMN last_retry_at DATETIME AFTER retry_count,
ADD COLUMN last_error TEXT AFTER last_retry_at;

-- Add indexes for recovery queries
CREATE INDEX idx_status_created ON split_payout_request(status, created_at);
CREATE INDEX idx_retry_count ON split_payout_request(retry_count);

-- Backfill existing records (if any) with default status
UPDATE split_payout_request
SET status = 'changenow_completed'
WHERE status IS NULL;
```

Step 2: Test Migration on Staging Database
-------------------------------------------
1. Backup staging database
2. Run migration script
3. Verify schema changes
4. Test queries:
   ```sql
   -- Should return 0 rows on fresh migration
   SELECT * FROM split_payout_request WHERE status = 'pending_changenow';

   -- Should work without errors
   UPDATE split_payout_request SET retry_count = 1 WHERE unique_id = 'TEST123';
   ```

Step 3: Run Migration on Production Database
---------------------------------------------
1. Backup production database
2. Schedule during low-traffic window (2 AM UTC)
3. Run migration script
4. Verify no errors
5. Monitor for 24 hours


PHASE 2: UPDATE GCWEBHOOK (Week 1, Days 3-4)
---------------------------------------------

Step 1: Modify Token Decoding
------------------------------
File: GCWebhook10-16/tph10-16.py

Location: After decoding success_url token

```python
# Decode token
user_id, closed_channel_id, wallet_address, payout_currency, payout_network, sub_time, sub_price = decode_token(token)

# (Existing code continues...)
```

Step 2: Modify split_payout_request Insert
-------------------------------------------
File: GCWebhook10-16/tph10-16.py

Location: After granting channel access

BEFORE:
```python
db.execute("""
    INSERT INTO split_payout_request (unique_id, subscription_price, timestamp)
    VALUES (?, ?, NOW())
""", unique_id, subscription_price)
```

AFTER:
```python
db.execute("""
    INSERT INTO split_payout_request (
        unique_id,
        user_id,
        subscription_price,
        open_channel_id,
        closed_channel_id,
        client_wallet_address,
        client_payout_currency,
        client_payout_network,
        status,
        retry_count,
        created_at
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, 'pending_changenow', 0, NOW())
""",
    unique_id,
    user_id,
    subscription_price,
    open_channel_id,  # May need to parse from somewhere
    closed_channel_id,
    wallet_address,
    payout_currency,
    payout_network
)
```

Step 3: Test GCWebhook Changes
-------------------------------
1. Deploy to staging
2. Trigger test payment
3. Verify split_payout_request has all fields populated
4. Verify status = "pending_changenow"


PHASE 3: UPDATE GCSPLIT (Week 1, Days 4-5)
-------------------------------------------

Step 1: Add Status Update on ChangeNow Failure
-----------------------------------------------
File: GCSplit10-21/tps10-21.py

Location: After ChangeNow rate query failure

```python
rate = get_changenow_rate(...)
if rate is None:
    # Update database before returning error
    db.execute("""
        UPDATE split_payout_request
        SET status = 'changenow_failed',
            retry_count = retry_count + 1,
            last_retry_at = NOW(),
            last_error = 'ChangeNow rate API unavailable'
        WHERE unique_id = ?
    """, unique_id)

    return jsonify({"error": "ChangeNow API unavailable"}), 503
```

Step 2: Add Status Update on ChangeNow Success
-----------------------------------------------
File: GCSplit10-21/tps10-21.py

Location: After successful ChangeNow transaction creation

```python
# Create ChangeNow transaction
transaction = create_changenow_transaction(...)

if transaction:
    # Insert to split_payout_que (existing code)
    db.execute("""INSERT INTO split_payout_que ...""")

    # ⭐ NEW: Update split_payout_request status
    db.execute("""
        UPDATE split_payout_request
        SET status = 'changenow_completed',
            retry_count = retry_count + 1,
            last_retry_at = NOW(),
            last_error = NULL
        WHERE unique_id = ?
    """, unique_id)

    # Create HostPay task (existing code)
    create_hostpay_task(...)
```

Step 3: Test GCSplit Changes
-----------------------------
1. Deploy to staging
2. Simulate ChangeNow failure (block API in firewall)
3. Verify status updated to "changenow_failed"
4. Simulate ChangeNow success
5. Verify status updated to "changenow_completed"


PHASE 4: CONFIGURE EXTENDED CLOUD TASKS RETRY (Week 2, Day 1)
--------------------------------------------------------------

Step 1: Update Queue Configuration
-----------------------------------
```bash
gcloud tasks queues update split-payment-queue \
    --location=us-central1 \
    --max-attempts=10 \
    --min-backoff=5s \
    --max-backoff=300s \
    --max-doublings=6
```

Step 2: Verify Configuration
-----------------------------
```bash
gcloud tasks queues describe split-payment-queue --location=us-central1
```

Expected output:
```
rateLimits:
  maxDispatchesPerSecond: 100
retryConfig:
  maxAttempts: 10
  minBackoff: 5s
  maxBackoff: 300s
  maxDoublings: 6
```

Step 3: Test Retry Behavior
----------------------------
1. Stop GCSplit service temporarily
2. Trigger test payment
3. Observe Cloud Tasks retry pattern
4. Verify retries continue for ~30 minutes
5. Restart GCSplit, verify task succeeds


PHASE 5: CREATE RECOVERY JOB SERVICE (Week 2, Days 2-4)
--------------------------------------------------------

Step 1: Create New Cloud Run Service
-------------------------------------
File: GCRecovery10-21/recovery.py

```python
from flask import Flask, jsonify
import os
from google.cloud import secretmanager
# ... (See pseudo-code in Section 6)

app = Flask(__name__)

@app.route('/recover_orphaned_payments', methods=['POST'])
def recover_orphaned_payments():
    # Implementation from Section 6
    pass

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)
```

Step 2: Create Dockerfile
--------------------------
File: GCRecovery10-21/Dockerfile

```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 540 recovery:app
```

Step 3: Deploy to Cloud Run
----------------------------
```bash
cd GCRecovery10-21
gcloud run deploy gcrecovery10-21 \
    --source . \
    --region us-central1 \
    --platform managed \
    --allow-unauthenticated=false \
    --timeout=540 \
    --memory=512Mi
```

Step 4: Test Recovery Endpoint
-------------------------------
1. Manually create orphaned payment in database
2. Call recovery endpoint
3. Verify payment recovered


PHASE 6: CONFIGURE CLOUD SCHEDULER (Week 2, Day 5)
---------------------------------------------------

Step 1: Create Service Account for Scheduler
---------------------------------------------
```bash
gcloud iam service-accounts create gcrecovery-scheduler \
    --display-name="GCRecovery Scheduler SA"

gcloud run services add-iam-policy-binding gcrecovery10-21 \
    --member="serviceAccount:gcrecovery-scheduler@PROJECT.iam.gserviceaccount.com" \
    --role="roles/run.invoker" \
    --region=us-central1
```

Step 2: Create Scheduler Job
-----------------------------
```bash
gcloud scheduler jobs create http recover-orphaned-payments \
    --schedule="*/5 * * * *" \
    --uri="https://gcrecovery10-21-xxx.run.app/recover_orphaned_payments" \
    --http-method=POST \
    --oidc-service-account-email=gcrecovery-scheduler@PROJECT.iam.gserviceaccount.com \
    --location=us-central1 \
    --time-zone="America/New_York"
```

Step 3: Verify Scheduler
-------------------------
```bash
# List jobs
gcloud scheduler jobs list --location=us-central1

# Manually trigger (test)
gcloud scheduler jobs run recover-orphaned-payments --location=us-central1

# Check logs
gcloud logging read "resource.type=cloud_scheduler_job" --limit=10
```


PHASE 7: MONITORING & ALERTING (Week 3)
----------------------------------------

Step 1: Create Monitoring Dashboard
------------------------------------
Metrics:
- Count of payments in each status
- Average retry_count
- Recovery job execution time
- Recovery job success rate

Step 2: Create Alerts
----------------------
```bash
# Alert: Stuck payments
gcloud alpha monitoring policies create \
    --display-name="Stuck ChangeNow Payments" \
    --condition-threshold-value=10 \
    --condition-threshold-duration=3600s \
    --notification-channels=EMAIL_CHANNEL_ID

# Alert: Recovery job failure
gcloud alpha monitoring policies create \
    --display-name="Recovery Job Failed" \
    --condition-threshold-value=2 \
    --condition-threshold-duration=600s \
    --notification-channels=PAGERDUTY_CHANNEL_ID
```

Step 3: Document Runbook
-------------------------
File: CHANGENOW_RECOVERY_RUNBOOK.txt
- How to check for stuck payments
- How to manually retry
- How to investigate failures
- Escalation procedures

================================================================================
10. MIGRATION STRATEGY
================================================================================

DEPLOYMENT APPROACH: ZERO-DOWNTIME MIGRATION
---------------------------------------------

Week 1: Preparation
- Day 1-2: Database schema update
- Day 3-4: Code changes (GCWebhook, GCSplit)
- Day 5: Testing on staging

Week 2: Rollout
- Day 1: Deploy to production (20% traffic)
- Day 2: Increase to 50% traffic
- Day 3: Increase to 100% traffic
- Day 4-5: Recovery job deployment

Week 3: Stabilization
- Monitor for issues
- Fine-tune retry parameters
- Create dashboards and alerts


ROLLBACK PLAN
-------------

If issues arise:

Immediate rollback (< 5 minutes):
```bash
gcloud run services update gcwebhook10-16 \
    --image=gcr.io/PROJECT/gcwebhook10-16:v-pre-recovery \
    --region=us-central1

gcloud run services update gcsplit10-21 \
    --image=gcr.io/PROJECT/gcsplit10-21:v-pre-recovery \
    --region=us-central1
```

Database rollback (if needed):
- Database schema changes are ADDITIVE (don't break existing code)
- New columns can remain NULL for old code paths
- No rollback needed unless critical issue


TESTING CHECKLIST
-----------------

✅ Test 1: Normal flow (ChangeNow available)
✅ Test 2: ChangeNow down for 2 minutes (Cloud Tasks retry succeeds)
✅ Test 3: ChangeNow down for 1 hour (recovery job succeeds)
✅ Test 4: Multiple orphaned payments (recovery job batch processing)
✅ Test 5: Permanent ChangeNow failure (max retries exceeded, alert sent)
✅ Test 6: Database insert failure (error handling)
✅ Test 7: Recovery job failure (retry on next run)
✅ Test 8: Manual recovery (admin intervention)

================================================================================
11. MONITORING & ALERTING
================================================================================

KEY METRICS TO MONITOR
-----------------------

Metric 1: Orphaned Payment Count
---------------------------------
Query:
```sql
SELECT COUNT(*) FROM split_payout_request
WHERE status IN ('pending_changenow', 'changenow_failed')
```

Normal: 0-5
Warning: > 10
Critical: > 50

Cause of spike: ChangeNow outage, recovery job not running


Metric 2: Average Retry Count
------------------------------
Query:
```sql
SELECT AVG(retry_count) FROM split_payout_request
WHERE status = 'changenow_completed'
AND created_at > NOW() - INTERVAL 1 DAY
```

Normal: 0-2 (most payments succeed on first or second try)
Warning: > 5
Critical: > 10

Cause of spike: ChangeNow having reliability issues


Metric 3: Permanent Failure Count
----------------------------------
Query:
```sql
SELECT COUNT(*) FROM split_payout_request
WHERE status = 'changenow_permanent_failure'
AND created_at > NOW() - INTERVAL 7 DAY
```

Normal: 0
Warning: > 1
Critical: > 5

Cause: Extended ChangeNow outage (> 8 hours) or configuration issue


Metric 4: Recovery Job Success Rate
------------------------------------
Log-based metric: % of recovery job runs that complete successfully

Normal: > 95%
Warning: < 90%
Critical: < 80%


ALERTING POLICIES
-----------------

Alert 1: High Orphaned Payment Count
-------------------------------------
Severity: WARNING
Condition: > 10 payments stuck for > 1 hour
Action: Email ops team
Message: "10+ payments stuck in pending_changenow status"

Alert 2: Permanent Failure Detected
------------------------------------
Severity: CRITICAL
Condition: Any payment reaches "changenow_permanent_failure" status
Action: PagerDuty + Email
Message: "Payment {unique_id} requires manual intervention"

Alert 3: Recovery Job Not Running
----------------------------------
Severity: CRITICAL
Condition: No recovery job execution in last 15 minutes
Action: PagerDuty
Message: "Recovery job missed 3 scheduled runs"

Alert 4: ChangeNow API Degradation
-----------------------------------
Severity: WARNING
Condition: Average retry_count > 5 for 30 minutes
Action: Email
Message: "ChangeNow API experiencing issues"


DASHBOARD WIDGETS
-----------------

Widget 1: Payment Status Distribution (Pie Chart)
--------------------------------------------------
Query:
```sql
SELECT status, COUNT(*) as count
FROM split_payout_request
WHERE created_at > NOW() - INTERVAL 24 HOUR
GROUP BY status
```

Shows: How many payments in each status


Widget 2: Retry Count Histogram
--------------------------------
Shows: Distribution of retry_count values
Insight: How many retries typically needed


Widget 3: Recovery Job Execution Timeline
------------------------------------------
Shows: Recovery job runs over time, success/failure
Insight: Is recovery job running reliably?


Widget 4: Orphaned Payment Age
-------------------------------
Shows: How long payments have been stuck
Insight: Are old payments being recovered?

================================================================================
12. COST-BENEFIT ANALYSIS
================================================================================

IMPLEMENTATION COST
-------------------

Development time: 2-3 weeks × $100/hour × 40 hours = $4,000 - $6,000
Cloud Scheduler: $0.10/month (free tier)
Additional Cloud Run: $10/month (recovery service)
Database storage: $5/month (additional columns)
Total one-time: $4,000 - $6,000
Total recurring: $15/month


BENEFIT ANALYSIS
----------------

Without recovery mechanism:
- Lost client payouts: $4,000/year
- Support overhead: $15,000 - $30,000/year
- Total annual cost: $19,000 - $34,000

With recovery mechanism:
- Lost client payouts: $0/year (99.9% recovery)
- Support overhead: $1,000/year (rare failures)
- Total annual cost: $1,000/year + $180/year infrastructure = $1,180/year

Annual savings: $19,000 - $34,000 - $1,180 = $17,820 - $32,820


ROI CALCULATION
---------------

Investment: $6,000 one-time + $180/year
Annual benefit: $17,820 - $32,820
ROI: (Annual benefit / Investment) × 100
ROI: 297% - 547%

Payback period: 6,000 / ((17,820 + 32,820) / 2) = 0.24 years = 3 months


RISK REDUCTION
--------------

Probability of catastrophic failure (before):
- P(ChangeNow down > 3 minutes) × P(payment during outage) = 5% × 50% = 2.5% monthly

Expected monthly impact (before): 2.5% × 1000 payments × $23.75 = $594

Probability of catastrophic failure (after):
- < 0.1% (only if recovery job also fails)

Expected monthly impact (after): 0.1% × 1000 × $23.75 = $24

Risk reduction: $594 - $24 = $570/month = $6,840/year


CONCLUSION
----------

Implementation of database-first recovery mechanism:
✅ Pays for itself in 3 months
✅ Saves $17,820 - $32,820 annually
✅ Reduces risk by 95%
✅ Provides peace of mind (no lost payments)
✅ Improves client trust and satisfaction

**STRONGLY RECOMMENDED for immediate implementation**

================================================================================
END OF DOCUMENT
================================================================================

Generated: October 2025
Version: 1.0
For: TelegramFunnel Payment System

This document addresses a CRITICAL architectural oversight and provides
a comprehensive solution to prevent lost client payouts due to extended
ChangeNow API downtime.

Related Documentation:
- CLOUD_TASKS_IMPLEMENTATION_GUIDE.txt - Overall Cloud Tasks architecture
- CHANGENOW_API_RESILIENCE_ANALYSIS.txt - ChangeNow retry strategies
- GCSPLIT_TO_GCHOSTPAY_TOKEN_FLOW.txt - Payment splitting flow

PRIORITY: CRITICAL - Implement immediately to prevent financial loss

================================================================================
